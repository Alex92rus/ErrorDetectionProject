{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1319\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVQAAAEaCAYAAABOwK+pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNTMrECdUM7MC+f8RqcwQhIlcIQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9c82255ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {(0, 1): 373, (1, 0): 282, (0, 0): 138, (1, 1): 526})\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import csv\n",
    "import fce_api as fd\n",
    "import itertools\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import settings\n",
    "\n",
    "#for jupyter notebook\n",
    "import scipy\n",
    "from sklearn import metrics\n",
    "\n",
    "def full_evaluation_table(confusion_matrix, classes=[]):\n",
    "    \"\"\"\n",
    "    Produce a pandas data-frame with Precision, F1 and Recall for all labels.\n",
    "    Args:\n",
    "        confusion_matrix: the confusion matrix to calculate metrics from.\n",
    "        classes: the categories of the confusion matrix\n",
    "        \n",
    "    Returns:\n",
    "        a pandas Dataframe with one row per gold label, and one more row for the aggregate of all labels.\n",
    "    \"\"\"\n",
    "    labels = sorted(list({l for l, _ in confusion_matrix.keys()} | {l for _, l in confusion_matrix.keys()}))\n",
    "    gold_counts = defaultdict(int)\n",
    "    guess_counts = defaultdict(int)\n",
    "    for (gold_label, guess_label), count in confusion_matrix.items():\n",
    "        if gold_label != \"None\":\n",
    "            gold_counts[gold_label] += count\n",
    "            gold_counts[\"[All]\"] += count\n",
    "        if guess_label != \"None\":\n",
    "            guess_counts[guess_label] += count\n",
    "            guess_counts[\"[All]\"] += count\n",
    "\n",
    "    result_table = []\n",
    "    for label in labels:\n",
    "        if label != \"None\":\n",
    "            if len(classes) == len(labels):\n",
    "                result_table.append((classes[label], gold_counts[label], guess_counts[label], *evaluate(confusion_matrix, {label})))\n",
    "            else:\n",
    "                result_table.append((label, gold_counts[label], guess_counts[label], *evaluate(confusion_matrix, {label})))\n",
    "    result_table.append((\"[All]\", gold_counts[\"[All]\"], guess_counts[\"[All]\"], *evaluate(confusion_matrix)))\n",
    "    return pd.DataFrame(result_table, columns=('Label', 'Gold', 'Guess', 'Precision', 'Recall', 'F1'))\n",
    "\n",
    "\n",
    "def evaluate(conf_matrix, label_filter=None):\n",
    "    \"\"\"\n",
    "    Evaluate Precision, Recall and F1 based on a confusion matrix as produced by `create_confusion_matrix`.\n",
    "    Args:\n",
    "        conf_matrix: a confusion matrix in form of a dictionary from `(gold_label,guess_label)` pairs to counts.\n",
    "        label_filter: a set of gold labels to consider. If set to `None` all labels are considered.\n",
    "\n",
    "    Returns:\n",
    "        Precision, Recall, F1 triple.\n",
    "    \"\"\"\n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    for (gold, guess), count in conf_matrix.items():\n",
    "        if label_filter is None or gold in label_filter or guess in label_filter:\n",
    "            if gold == 'None' and guess != gold:\n",
    "                fp += count\n",
    "            elif gold == 'None' and guess == gold:\n",
    "                tn += count\n",
    "            elif gold != 'None' and guess == gold:\n",
    "                tp += count\n",
    "            elif gold != 'None' and guess == 'None':\n",
    "                fn += count\n",
    "            else:  # both gold and guess are not-None, but different\n",
    "                fp += count if label_filter is None or guess in label_filter else 0\n",
    "                fn += count if label_filter is None or gold in label_filter else 0\n",
    "    prec = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    f1 = 2 * prec * recall / (prec + recall) if prec * recall > 0 else 0.0\n",
    "    return prec, recall, f1\n",
    "\n",
    "# if the number of annotations is at least number judgements\n",
    "def test_annotation_dict(annot_dict, judgements):\n",
    "    for key in annot_dict.keys():\n",
    "        if len(annot_dict[key]) < judgements:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# create the confusion matrix\n",
    "def create_confusion_matrix(data, predictions):\n",
    "    \"\"\"\n",
    "    Produces a confusion matrix in a form of a dictionary from (gold_label,guess_label)` pairs to counts.\n",
    "    Args:\n",
    "        data: list containing the gold labels.\n",
    "        predictions: list containing the prediction labels\n",
    "\n",
    "    Returns:\n",
    "        confusion matrix in form of dictionary with counts for (gold_label, guess_label)\n",
    "    \"\"\"\n",
    "    confusion = defaultdict(int)\n",
    "    for y_gold, y_guess in zip(data, predictions):\n",
    "        confusion[(y_gold, y_guess)] += 1\n",
    "    return confusion\n",
    "\n",
    "# plot the confusion matrix\n",
    "def plot_confusion_matrix_dict(matrix_dict, classes=[], rotation=45, outside_label=''):\n",
    "    labels = set([y for y, _ in matrix_dict.keys()] + [y for _, y in matrix_dict.keys()])\n",
    "    sorted_labels = sorted(labels, key=lambda x: -x)\n",
    "    matrix = np.zeros((len(sorted_labels), len(sorted_labels)))\n",
    "    for i1, y1 in enumerate(sorted_labels):\n",
    "        for i2, y2 in enumerate(sorted_labels):\n",
    "            if y1 != outside_label or y2 != outside_label:\n",
    "                matrix[i1, i2] = matrix_dict[y1, y2]\n",
    "\n",
    "    threshold = matrix.max() / 2.\n",
    "    for i, j in itertools.product(range(matrix.shape[0]), range(matrix.shape[1])):\n",
    "        plt.text(j, i, matrix[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if matrix[i, j] > threshold else \"black\")\n",
    "\n",
    "    plt.imshow(matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.colorbar()\n",
    "    if (len(classes) != len(sorted_labels)):\n",
    "        classes = sorted_labels\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=rotation)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    plt.xlabel('predicted labels')\n",
    "    plt.ylabel('gold labels')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# extracts the amt_sentences along with their errors\n",
    "def extract_sentences_with_errors():\n",
    "    # open source file\n",
    "    with open(settings.TRAINING_DATA_FILE, 'r') as file:\n",
    "        # read the lines\n",
    "        readlines = file.readlines()\n",
    "        with open('amt_sentence_batch.csv', 'r') as amt_batch:\n",
    "            csv_reader = csv.DictReader(amt_batch)\n",
    "            with open('fce_amt.experiment_two.max.rasp.m2', 'w+') as destination:\n",
    "                for row in csv_reader:\n",
    "                    sentence = row['sentence']\n",
    "                    i = 0\n",
    "                    while i < len(readlines):\n",
    "                        if sentence == readlines[i][2:-1]:\n",
    "                            destination.write(readlines[i])\n",
    "                            i += 1\n",
    "                            while readlines[i][0] != 'S' and i < len(readlines):\n",
    "                                destination.writelines(readlines[i])\n",
    "                                i += 1\n",
    "                        else:\n",
    "                            i += 1\n",
    "\n",
    "\n",
    "# get annotations from turkers\n",
    "def get_annotations():\n",
    "    # sentence -> annotations\n",
    "    result_annotations = defaultdict(list)\n",
    "    with open(settings.AMT_FILE) as file:\n",
    "        csv_reader = csv.DictReader(file)\n",
    "        for row in csv_reader:\n",
    "            sentence = row['Input.sentence']\n",
    "            answer = json.loads(row['Answer.ChosenWord'])\n",
    "            for annotation in answer['selectedTokens']:\n",
    "                result_annotations[sentence].append(annotation['start'])\n",
    "    return result_annotations\n",
    "\n",
    "# compare the annotations with gold\n",
    "def compare_annotations(gold_sentences, annotation_labels):\n",
    "    \"\"\"\n",
    "    Produces gold and annotation error detection labels from given annotations and gold data\n",
    "    Args:\n",
    "        gold_sentences: a list  of tuples containing the sentences and the related gold error annotations.\n",
    "        annotation_labels: labels from the annotation representing the start index of the error\n",
    "\n",
    "    Returns:\n",
    "        gold and predicted labels\n",
    "    \"\"\"\n",
    "    gold = []\n",
    "    predicted = []\n",
    "    count = 0\n",
    "    for sentence in gold_sentences:\n",
    "        labels = annotations[sentence[0][1:]]\n",
    "        for label in labels:\n",
    "            counted = 0\n",
    "            error_spans = sentence[1]\n",
    "            if label == - 2 and len(error_spans) == 0:\n",
    "                gold.append(0)\n",
    "                predicted.append(0)\n",
    "                counted = 1\n",
    "            if label == -2 and len(error_spans) > 0:\n",
    "                gold.append(1)\n",
    "                predicted.append(0)\n",
    "                counted = 1\n",
    "            for error_span in error_spans:\n",
    "                if int(label) >= error_span[0] and int(label) < error_span[1]:\n",
    "                    gold.append(1)\n",
    "                    predicted.append(1)\n",
    "                    counted = 1\n",
    "            if (counted == 0):\n",
    "                gold.append(0)\n",
    "                predicted.append(1)\n",
    "                counted = 1\n",
    "    return gold, predicted\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    gold_data = fd.extract_data('fce_amt.experiment_two.max.rasp.m2')\n",
    "    annotations = get_annotations()\n",
    "    gold, predicted = compare_annotations(gold_data, annotations)\n",
    "    print(len(gold))\n",
    "    cm = create_confusion_matrix(gold, predicted)\n",
    "    plot_confusion_matrix_dict(cm, classes=['Error', 'No Error'])\n",
    "    precision_and_recall = full_evaluation_table(cm, classes=['No Error', 'Error'])\n",
    "    print(cm)\n",
    "    precision_and_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Gold</th>\n",
       "      <th>Guess</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No Error</td>\n",
       "      <td>511</td>\n",
       "      <td>420</td>\n",
       "      <td>0.328571</td>\n",
       "      <td>0.270059</td>\n",
       "      <td>0.296455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Error</td>\n",
       "      <td>808</td>\n",
       "      <td>899</td>\n",
       "      <td>0.585095</td>\n",
       "      <td>0.650990</td>\n",
       "      <td>0.616286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[All]</td>\n",
       "      <td>1319</td>\n",
       "      <td>1319</td>\n",
       "      <td>0.503412</td>\n",
       "      <td>0.503412</td>\n",
       "      <td>0.503412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label  Gold  Guess  Precision    Recall        F1\n",
       "0  No Error   511    420   0.328571  0.270059  0.296455\n",
       "1     Error   808    899   0.585095  0.650990  0.616286\n",
       "2     [All]  1319   1319   0.503412  0.503412  0.503412"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_and_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "twod = [[1, 2, 3], [4, 5, 6]]\n",
    "print(len(twod))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[0] * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8959183673469387\n",
      "A3NNPTNU2E14NU  : (accuracy:  0.5 , count:  1 )\n",
      "A11W4M93DE3L1M  : (accuracy:  0.6 , count:  3 )\n",
      "A3MIIUL4O2DPY7  : (accuracy:  0.4166666666666667 , count:  1 )\n",
      "A2XPWIUYIWM1VW  : (accuracy:  0.5263157894736842 , count:  2 )\n",
      "A3MSWCN6CN7WTC  : (accuracy:  0.4444444444444444 , count:  1 )\n",
      "A3SKCD4S91W2HE  : (accuracy:  0.6666666666666666 , count:  1 )\n",
      "A1SL65Z68BK1UT  : (accuracy:  0.38461538461538464 , count:  1 )\n",
      "A238TPXOPQKZS1  : (accuracy:  0.45 , count:  3 )\n",
      "A555M7PR0JWNX  : (accuracy:  0.36363636363636365 , count:  1 )\n",
      "AEWUXHS3RHADA  : (accuracy:  0.5769230769230769 , count:  4 )\n",
      "A3VE5OH94HYHET  : (accuracy:  0.48214285714285715 , count:  7 )\n",
      "A2PRSLHM2YT07L  : (accuracy:  0.5 , count:  3 )\n",
      "A34MRQ1OP87XC6  : (accuracy:  0.4 , count:  1 )\n",
      "A1I9EVJP8W169U  : (accuracy:  0.5 , count:  1 )\n",
      "A1VD6JSPKSCTJB  : (accuracy:  0.75 , count:  1 )\n",
      "A9HQ3E0F2AGVO  : (accuracy:  1.0 , count:  1 )\n",
      "A26XN1TM6CV01T  : (accuracy:  0.5217391304347826 , count:  3 )\n",
      "A3IUFKJAROSMK  : (accuracy:  1.0 , count:  2 )\n",
      "ASWFLI3N8X72G  : (accuracy:  0.5 , count:  1 )\n",
      "A3D6IPJ4RBCNVY  : (accuracy:  0.4166666666666667 , count:  2 )\n",
      "A3T71W88062DB7  : (accuracy:  0.8333333333333334 , count:  1 )\n",
      "A1KSE9KF1WP564  : (accuracy:  0.5952380952380952 , count:  6 )\n",
      "A1KRSKHQC8MPAM  : (accuracy:  0.5925925925925926 , count:  5 )\n",
      "A3IIFBETASAM87  : (accuracy:  0.3877551020408163 , count:  5 )\n",
      "A3HMBHM8HJLKRD  : (accuracy:  0.7142857142857143 , count:  1 )\n",
      "A3UUH3632AI3ZX  : (accuracy:  0.5 , count:  1 )\n",
      "A3TQUS51JKYUUE  : (accuracy:  0.4090909090909091 , count:  1 )\n",
      "A2VIGMJ1CENNNE  : (accuracy:  0.2727272727272727 , count:  2 )\n",
      "A2PPN440GZL488  : (accuracy:  0.2647058823529412 , count:  4 )\n",
      "A1ESCPVSM3GQ95  : (accuracy:  0.7027027027027027 , count:  5 )\n",
      "A2IFPAX33G7JZJ  : (accuracy:  0.5205479452054794 , count:  5 )\n",
      "A2U8PL0H9LR2BP  : (accuracy:  0.6 , count:  2 )\n",
      "A19V3A2N7GWL77  : (accuracy:  0.8 , count:  1 )\n",
      "A1YTP3NEKN5LG3  : (accuracy:  0.6285714285714286 , count:  3 )\n",
      "A1I7DQP8IAGFNN  : (accuracy:  0.6666666666666666 , count:  1 )\n",
      "A1Q8V9050IW4XG  : (accuracy:  0.5625 , count:  3 )\n",
      "AZTIHNWNL4G86  : (accuracy:  0.3974358974358974 , count:  3 )\n",
      "A142HU5YGNJZ7F  : (accuracy:  0.6470588235294118 , count:  1 )\n",
      "A23OR0D1FCUVMM  : (accuracy:  1.0 , count:  1 )\n",
      "A315ZG72CPNAHV  : (accuracy:  0.7142857142857143 , count:  2 )\n",
      "AZTB9EIA5XHKY  : (accuracy:  0.7142857142857143 , count:  3 )\n",
      "A2J6K14FVB2N3E  : (accuracy:  0.75 , count:  1 )\n",
      "A3VQRO265I4X5S  : (accuracy:  0.7222222222222222 , count:  3 )\n",
      "Number of turkers:  43\n",
      "Counts:  100\n",
      "Average Count:  2.3255813953488373\n",
      "Average Accuracy:  0.5812982107729654\n",
      "Pearson Correlation:  (0.76418797111585923, 5.4540151510612247e-95)\n",
      "Spearman Coefficient:  SpearmanrResult(correlation=0.76418797111585934, pvalue=5.4540151510589986e-95)\n",
      "Cohen's Kappa:  0.763786226062\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVMAAAEaCAYAAACsHLTQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xm8lnP+x/HX+1SISoSa0YghS0SWFCGDLCHLkCXGOox9\nZzKGQVTDWMYwM8bW2GMYzFiqiVAU7Qq/bFEoe2Vt+fz+uK6T23GWu3Puc+77Or2f87gfXdf3vq77\n/pyT+fTdru9XEYGZmdVNWbEDMDNrDJxMzcwKwMnUzKwAnEzNzArAydTMrACcTM3MCqBpsQMoJkme\nF2ZWjyJChfosrdAqWDg/n0tnRsS6hfrefGl5nmcqKW54/q1ih1Fwj996Hb2PO7PYYRTcUVt3KHYI\n9eLKAZdy4UWXFDuMgmvVvElhk6kUK215Wo3XfTPxhoJ+b76W65qpmWWMGjxH5s3J1MyyQ6U7zONk\n2gh13LJ7sUOwZbDjTj2LHUJ2uGZqDanjVk6mWbLjTjsXO4TscM3UzKwAypoUO4IqOZmaWXa4mW9m\nVgBu5puZFYBrpmZmBeCaqZlZAXgAysysAFwzNTMrgLLS7TMt3TRvZlaRymp+VXab1F7SSEnTJE2V\ndHpavoWkFyRNlDRO0jY59/SXNEPSq5J2ryk010zNLDtqP5q/CDg7IiZJagG8LGk48EfgkogYJmkv\n4CrgF5I6AX2BTYD2wAhJHaOaZfacTM0sO2o5ABURHwIfpscLJL0G/BRYAqyaXtYamJ0e9wHui4hF\nwDuSZgDbAmOr+g4nUzPLjgIMQElaF+hCkhjPAp6S9CdAwPbpZWsDL+TcNjstq5KTqZllRyXN/MWf\nvsmST9/M83a1AB4EzkhrqCelx/+WdBBwG9CrNqE5mZpZdlRSM23SpiNN2nRcer74reGV3yo1JUmk\nd0bEI2nxURFxBkBEPCjplrR8NvCznNvb830XQKU8mm9m2SHV/KrabcD0iLg+p2y2pJ7JR2tXYEZa\n/ihwqKQVJK0HbACMq+7DXTM1s+yoZZ+ppB5AP2CqpIlAABcCvwb+LKkJ8A1wAkBETJc0FJgOLARO\nrm4kH5xMzSxLaj+aPxqo6uZtKiuMiIHAwHy/w8nUzLLDj5OamRWAl+AzMysA10zNzArANVMzswLw\neqZmZnUn10zNzOrOydTMrBBKN5c6mZpZdrhmamZWAE6mZmYFUFbmeaZmZnVXuhVTJ1Mzyw43883M\nCsDJ1MysAJxMzcwKQGVOpmZmdeaaqZlZATiZmpkVgJOpmVkhlG4udTI1s+wo5SegSjcyM7MKJNX4\nquK+9pJGSpomaaqk0yu8f46kJZJWzynrL2mGpFcl7V5TbK6Zmllm1KHPdBFwdkRMktQCGC9pWES8\nJqk90AuYmfM9mwB9gU2A9sAISR0jIqr6AifTjLl74AVMGzOSlquvQf8hTwDw31uuZcpzwykrK6Pl\namtwxO+uolWbNfn0w9kM6NeLth3WB2DdTl045NzLixn+cm32rFmcePzRzJ07h7KyMo465nhOOuU0\npk6ZzFmnn8JXX33JOh06cMvtd9GiRYtih1uaaplLI+JD4MP0eIGkV4G1gdeAa4HzgEdzbtkPuC8i\nFgHvSJoBbAuMreo7nEwzpnvvg+h50FHcOeCcpWW7HX4Cex9/FgCjHhzCE7dfzyHnDgBgzfYduOC2\nx4oSq/1Q06ZNuXLw1Wy+RRcWLFhAzx7bssuuu3HayScycPDVbNdjB+6+8w6uu+YqLrr40mKHW5IK\nMZovaV2gCzBWUh/gvYiYWuGz1wZeyDmfnZZVyX2mGbP+Fl1ZueWqPyhbceVVlh5/+/VXKGc73Gpa\nJdbA2rZrx+ZbdAGgRYsWbLjhRrz//mzeenMG2/XYAYCdf7Ebj/77oWKGWdJq22eac38L4EHgDGAx\ncCFwSSFiq/eaqaS2wHXANsDnwBzgzIh4owG+ewvgpxHxRH1/V7H95+Y/Me7Jh2jeshWn//mepeWf\nfjCbwcfuS/NVWrL38Wex/hZdixillZs58x2mTplM1227s/Emm/L4fx6l9z59ePhfD/D+7FnFDq9k\nVfY46Tezp/Lt7FdqvldqSpJI74yIRyRtBqwLTFaShdsDEyRtS1ITXSfn9vZpWZUaomb6MDAyIjpG\nRFegP9C2ppsk/WhPVy17Hb8L0HsZ78mkfU44h8seGs02vfZj1INDAGjVZk0u+9fzXHDbYxxw6oUM\nufRMvv3qyyJHagsWLOBXh/dl8NXX0qJFC2782z+4+e830bNHN7786kuarbBCsUMsWZXVRJu335zW\n3Q5f+qrGbcD0iLgeICJeiYh2EfHziFgPmAVsGRFzSfpPD5G0gqT1gA2AcdV9eL0mU0m/AL6LiH+U\nl0XE1IgYLemqdIrCZEl90+t7SnpW0iPANEkdJL0maYikqUB7Sb0kjZH0sqT7Ja2c3ttV0mhJkyS9\nKKkVcBnQV9IESQfX589aKrbp1YdJo54EoGmzFVi5VdIl8LONNmONtTsw9723ixnecm/RokUcefjB\nHHLYEey9734AdNxwI/792JOMGj2WXx58COutt36RoyxddZga1QPoB+wiaWKaE/ascFmQDnFFxHRg\nKDAdeBw4ubqRfKj/Zv5mwPiKhZIOBDaPiM6S1gJekjQqfXtLYNOIeFdSB5J/EY6MiJcktQEuAnaN\niK8lnQ+cLWkwcB9wcERMSPtFvgYuBraOiNMrxpBlEfGDvtCPZr3Dmu3XBWDKc8Np12EDABZ8/ikr\nt2pNWVkZH89+l49mz6TNT9ep7COtgZx84nFsvHEnTj71+/8kP/7oI9ZYc02WLFnCVYOu4Lhfn1DE\nCEtbbQegImI08KPWboVrfl7hfCAwMN/vKNZo/g7AvQARMVfSM0BXYD4wLiLezbl2ZkS8lB53BzoB\no9MmfzOSEbeNgPcjYkL6mQugtJ/jra07/nAGMyaO5at5n3PxgT3ofdyZTHvhaea8+xZlZU1Yvd3a\nS0fy35g8jsdvuY4mzZohiUPPG8DKLVsV+SdYfr04ZjRD77uHTTfrzA7dt0YSF186gDdmzOAff78J\nSfTZ7wD6HXl0sUMtWaX8/+n6TqbTgIPyuC73N1SxU+/LCtcNi4h+P7g56Uiu1W/58VuvW3rcccvu\ndNyqe20+psEc/Yfrf1TWfe/KezC69NyTLj0rtmSsWLpv34PPv1z4o/Jeu+/JSaecVoSICuu5Z5/h\nuWdH1XxhHSy365lGxEhJV0g6PiJuAZDUmWRU/xBJ/wTaADsC55I8bVBR7m/vReAvktaPiDfT/tK1\ngdeBdpK2jojxOc38+UC1VbHex51Zx5/SzAB23Glndtxp56Xng664rODfUco104YYzT8A6CXpjXQQ\n6UrgbmAKMBkYAZyXjqBVZmnnYER8DBwN3CtpMjAG2CgiFgKHkCTaScAwYEXgaaDT8jQAZdaYSTW/\niqXe+0zTx7gOqeStC9JX7rWjgFE55zOBzStc8wzJY10Vv2c8sF2F4q8qu9bMsqmUa6Z+nNTMMqOE\nc6mTqZllR9nyOgBlZlZITqZmZgXgZr6ZWQF4AMrMrABKOJc6mZpZdrhmamZWAB6AMjMrANdMzcwK\noIRzqZOpmWWHa6ZmZgVQwrnUydTMssMDUGZmBeBmvplZAZRwLnUyNbPscM3UzKwASjiXNsi2JWZm\nBSGpxlcV97WXNFLSNElTJZ2elq8maZik1yU9JWnVnHv6S5oh6VVJu9cUm5OpmWVGWZlqfFVhEXB2\nRGxKsr3RKZI2Bn4LjIiIjYCRQH8ASZ2AviSbfO4F3KQa+hicTM0sM2pbM42IDyNiUnq8AHgVaA/s\nBwxJLxsC7J8e9wHui4hFEfEOMIMa9pNzMjWzzCjE7qSS1gW6kGwd3zYi5sDSzT/XSi9bG3gv57bZ\naVmVPABlZplR19F8SS2AB4EzImKBpKhwScXzvDmZmllmVJZLP5sxgc/fmJjHvWpKkkjvjIhH0uI5\nktpGxBxJ7YC5afls4Gc5t7dPy6rkZGpmmVHZAFObjbamzUZbLz2f+dRtVd1+GzA9Iq7PKXsUOBoY\nDBwFPJJTfreka0ma9xsA46qNrabgJR0sqWV6fJGkhyRtVdN9ZmaFVibV+KqMpB5AP2AXSRMlTZC0\nJ0kS7SXpdWBXYBBAREwHhgLTgceBkyOi2i6AfGqmv4+IByTtAOwGXAX8FeiWzw9vZlYote0yjYjR\nQJMq3t6tinsGAgPz/Y58RvMXp3/uDdwcEf8FVsj3C8zMCqW2U6MaQj7JdLakvwOHAI9LWjHP+8zM\nCqpMNb+KFlse1/QFngL2iIjPgdWB8+o1KjOzStThCah6V2WfqaTVc06fySn7Fni5fsMyM/sxUbor\nnVQ3ADWeZAJrZdEH8PN6icjMrAolvNB+1ck0ItZryEDMzGpSyuuZ5jPPVJKOkPT79HwdSdU+8G9m\nVh8K8Wx+fclnAOomkiWrDk/P5wM31ltEZmZVqO2k/YaQz6T9bhGxlaSJABHxmSTPMzWzBpf13UkX\nSmpCupqKpDWBJfUalZlZJUq4yzSvZPpn4GGgraQrgIOAi+o1KjOzShSzGV+TGpNpRNwtaTzJIgAA\n+0fEq/UblpnZj5VuKs1/Cb6VSRYJCKB5/YVjZla1rE+Nuphkb5TVgTWA2yW5mW9mDa5JmWp8FUs+\nNdN+wBYR8Q2ApEHAJGBAfQZmZlZRCVdM80qm7wMrAd+k5ytSw/L9Zmb1oZSb+dUtdHIDSR/pF8A0\nScPT817UsHy/mVl9KOFpptXWTMtXhhpPMjWq3DP1Fo2ZWTUyWTONiCENGYiZWU2aZDGZlpPUkWQf\nlE4kfacARISX4DOzBlXCuTSvhU5uJ9lAbxHwC+CfwF31GZSZWWWyvgdU84j4H6CImBkRfyDZXM/M\nrEHVZQk+SbdKmiNpSoXy0yS9KmlqOvWzvLy/pBnpe7vXFFs+U6O+lVQGzJB0Ksm0qBZ53GdmVlB1\nfDb/duAGktY1AJJ2BvYFOkfEIklrpOWbkOx/twnQHhghqWNERJWx5RHAGSSPk54ObA0cCRxVqx/F\nzKwO6lIzjYjngc8qFJ8EDIqIRek1H6fl+wH3RcSiiHgHmAFUuyh+PgudvJQeLgCOqen6rDm+m3dn\nyYrVup5a7BCsyOphNH9DYCdJVwJfA+dGxHhgbeCFnOtmp2VVqm7S/mOka5hWJiL6LEvEZmZ1VQ8D\nTE2B1SKiu6SuwAPUcrPQ6mqmV9fmA83M6ktlT0DNmjqOWa/U+qHM94CHIGmFS1osqQ1JTXSdnOva\nU8Nj9NVN2h9V2+jMzOpDZcl0nc23ZZ3Nv+/OHHt/tVvUiR8ui/pvYBdglKQNgRUi4hNJjwJ3S7qG\npHm/ATU8Rp/veqZmZkVXl2a+pHuAnYE2kt4FLgFuI1lWdCrwLfArgIiYLmkoMB1YCJxc3Ug+OJma\nWYY0yWf+URUi4vAq3jqyiusHkjz9mRcnUzPLjEzuAeXRfDMrNXWomNa7fEbzDwTa8f3z+IcBc+oz\nKDOzypRwxbTm0XxJf4qIbXLeekzSy1XcZmZWb0q5mZ9PrXkVSUsnsUpaD1il/kIyM6tcXR4nrW/5\nDECdBTwj6S2S+VkdgBPrNSozs0o0LeF9S/J5Nv/JdIHojdOi1yLi2/oNy8zsx0q4lV/taP6BVby1\nviQi4qF6isnMrFIlXDGttma6bzXvBenzrGZmDUWUbjatbjS/0S23Z2bZltWaKQCSViV5hnWntGgU\ncFlEfFGfgZmZVdSkhLNpPlOjbgPmkyzh3xeYR7L8v5lZgypTza9iyWdq1PoR8cuc80slTaqvgMzM\nqlLKo/n51Ey/lrRD+YmkHiTL+5uZNagyqcZXseRTMz0JGJL2nQr4FDi6PoMyM6tMCXeZ5jVpfxKw\nhaRW6fm8eo/KzKwS9bChXsHkM5p/doVzgC+A8WmiNTNrECWcS/Nq5m+Tvh5Lz/cBpgC/kfRARPyx\nvoIzM8uV6WY+ya58W0XEAgBJlwD/JZl3Oh5wMjWzBlHKS/Dlk0zXItloqtxCoG1EfC3JC56YWYMp\n4VyaVzK9Gxgr6ZH0fF/gHkmrkOzcZ2bWIDJdM42IyyU9AfRIi34TEeUr7fert8jMzCpoUrq5NL/d\nSdPk6a1KzKyoVIeaqaRbSQbQ50TE5mnZH0la298CbwLHlE//lNQfOBZYBJwREcOq+/xS3uzPzOwH\nlMerGrcDe1QoGwZsGhFdgBlAfwBJnUjWItkE2Au4STVkcidTM8uMujxOGhHPA59VKBsREUvS0xdJ\nZi8B9AHui4hFEfEOSaLdttrYavkzmZk1uDrWTGtyLPB4erw28F7Oe7PTsirl1WdqZlYKyupp1r6k\n3wELI+Le2n6Gk6mZZUZlTelpL49h+ssv1PozJR0N9AZ2ySmeDfws57x9WlYlJ1Mzy4zKxoA269qD\nzbr2WHr+r5uvrfYjyOkNkLQncB6wU4Vdlx8F7pZ0LUnzfgNgXHUf7GRqZplRl0a+pHuAnYE2kt4l\n2Y7pQmAFYHiaqF+MiJMjYrqkoSQPJi0ETo6IqO7znUzNLDPqMs80Ig6vpLjKLZgiYiAwMN/PdzI1\ns8zI9HqmZmalonRTqZOpmWVICVdMnUzNLDvKSrhu6mRqZpnhmqmZWQHINVMzs7rzaL6ZWQGUcC51\nMjWz7CjlZOol+DJs1qxZ7NlrF7baYlO26dKZm/5yAwAX/vZ8unTehG5bd+HQvr9k3rx5RY50+bVC\ns6Y8+89zeeHeC3hp6IVceMJeALRu2ZzHbjqFyQ//nkdvPIVWLVb6wX0/a7cac5+/mtOP2KWyj11u\nKY//FYuTaYY1bdqUwVddw4TJ03jm+Rf421//wuuvvcZuvXZnwuRpjB0/iQ026MhVg/N+Is4K7LuF\ni9jjhOvZ7rDBdDt0IHv06MQ2m3bg3GN25+mxr7PFAZcz6qXXOe/Y3X9w36CzD+Cp56cVKerSVaaa\nX0WLrXhfbXXVrl07tujSBYAWLVqw0cab8P77s9ll190oK0v+arft1p3Zs2YVM8zl3tffLARgxRWa\n0qRpEyKCfXbuzF2PjQXgrsfGsu/Omy+9fp+dO/P2rE+Y/tYHRYm3lNVlpf16j62hvkjSNZJOzzl/\nUtLNOedXSzqzoeJpbGa+8w5TJk+i67bdflD+zztuY/c99ypSVAbJ4hwv3HsB7wy/kpEvvsb46e+y\nVptWzP10PgBzPpnPWm1aAbBK8xU4+6jduOLmx0t6GlCxuJmfGA1sD5BuTLUGsGnO+9sDY8pPJDVp\nwNgybcGCBRx+yEFcfc31tGjRYmn54IFX0LRZMw49rLLFcqyhRATbHTaYDfb8Pdts2oFNft6Oiqu5\nLVmSnP/uxN7ccPfTS2uzpTzgUgyl3MxvyNH8MUD5qq2bAq8A7SStCnxNsgtgK0nPkmx6tRGwsaSz\ngWOAAG6NiOsldQCeAJ4nScKzgP0i4ltJXYFbgMXACGCviOjcUD9kQ1u0aBGHH3IQh/U7kn377Le0\n/M4hd/DkE4/z5PCRRYzOcs3/8hueHT+D3Xt0Yu4n81lr9ZbM/XQ+bdu05KO0ltq187rsv2sXrjhj\nf1q3WpnFi5fw9TcLufmB54ocfWko5dp6gyXTiPhA0kJJ7fm+Fro2sB0wD5hCsgjrliRbr74raSvg\nKKAr0AQYK+kZ4HOSla8PiYgTJN0P/BK4B7gNOC4ixkkaSJKEG60Tjz+WjTfpxKmnn7G0bNhTT3Lt\nNVcxfOSzrLjiikWMztq0XoWFixYzb8E3rLRiM3btvjFX3z6M/46aypF9uvGnO0ZwxL7d+M+oKQD0\nOu66pfdeeMJeLPjqWyfSHKVcU2/oeaZjgB4kyfRPJPuq9AC+IOkGABgXEe+mxzsAD0fENwCSHgJ2\nBB4D3o6Iqel144F101pui4go317gHmDv+v2RimfM6NHcd+/dbLZZZ7pvsyWS+MPlV3DOWafz3Xff\nsc+evYBkEOr6v9xU5GiXT+3WWJV/XHYkZWXJ4MiDwybw1PPTGTflHe7647H8ar/tePeDTzni/NuK\nHWomlHAuLUoy3R7YjKSZPws4hySZlq94/WWen5W7X8tioHyi3jL9vgdc9oelxzv13Jmdeu68LLcX\n1fY9evDlt4t/VL7HnjOKEI1VZtob77P94YN/VP7ZvK/Y+zd/qfbeK29+or7CqheL589myYJq95yr\nMz9O+r0xwLnAm+l+Kp9Jag10An4NVOzbfA64XdIgkmb+AcAR6Xs/+q1GxBeS5knqGhEvAYfWFNBF\nF/+htj+LmeVo0nJtmrT8fmv5xXNeKvyXlG4ubfB5plOBNsALFco+j4hPK14cEROBO4CX0ntujojJ\n5W9X8R3HA7dImgCsTFLrNbNGoJSnRqmGDfcyR9IqEfFlenwB0C4izqri2vh6YeP6+Ruz1bqeWuwQ\nbBl8M+lGIqJg2U1SjH3z8xqv67Z+64J+b74a40Ine0vqT/KzvQMcXdRozKxgSriV3/iSaUQMBYYW\nOw4zK7y6bPUs6SzgOGAJSffiMcAqwP1AB5LKV9+IqFXXoJ/NN7PMkGp+VX6ffgqcBmwVEZuTVCQP\nA34LjIiIjYCRQP/axuZkamaZoTxe1WgCrCKpKdAcmA3sBwxJ3x8C7F/b2JxMzSw7aplNI+J9kgeF\n3iVJol9ExAigbUTMSa/5EFirtqE1uj5TM2u8Kpv69PILz/Hyi9U/cpvOZ9+PpG/0C+ABSf348RTL\nWk/vcTI1s8yobFWobbffkW2333Hp+c3XD6rs1t2At8rns0t6mORpzDmS2kbEHEntgLm1jq22N5qZ\nNbjad5q+C3SXtFK6BOiuwHTgUb6fPnkU8EhtQ3PN1Mwyo7ZPOKWryD0ITCRZnW4icDPQEhgq6Vhg\nJtC3trE5mZpZZtRlnZOIuBS4tELxpyRdAHXmZGpmmeEnoMzMCqGEs6mTqZllRjF3H62Jk6mZZUbp\nplInUzPLkhLOpk6mZpYZ3p3UzKwASrjL1MnUzLLDydTMrADczDczKwDXTM3MCqCEc6mTqZllSAln\nUydTM8sM95mamRVAZYtDlwonUzPLDidTM7O6czPfzKwAPDXKzKwASjiXOpmaWXaohKumTqZmlhkl\nnEudTM0sO0o4l1JW7ADMzPIl1fyq/n6VSZog6dH0fDVJwyS9LukpSavWNjYnUzPLDOXxvxqcAUzP\nOf8tMCIiNgJGAv1rG5uTqZllRl1qppLaA72BW3KK9wOGpMdDgP1rG5uTqZllRh2b+dcC5wGRU9Y2\nIuYARMSHwFq1jc3J1Mwyo7bNfEl7A3MiYhLVj2NFNe9Vy6P5ZpYdlaTB0c+NYvRzo2q6swfQR1Jv\noDnQUtKdwIeS2kbEHEntgLm1Di2i1ok48yTF1wuX358/a1bremqxQ7Bl8M2kG4mIgs1mkhQfzV9Y\n43VrtmxW7fdK6gmcExF9JP0R+CQiBku6AFgtIn5bm/hcMzWzzKiHSfuDgKGSjgVmAn1r+0FOpmaW\nGWUFyKYRMQoYlR5/CuxW5w/FA1BmZgXhmqmZZYafzTczKwAvDm1mVgCumZqZFYCTqZlZAZRyM9+j\n+Y3Qs6OeKXYItgwWz59d7BAyo65L8NUnJ9NGyMk0W5YscDLNl/J4FYub+WaWHaXbyncyNbPsKMQT\nUPVluV/opNgxmDVmBV7o5B2gQx6XzoyIdQv1vflarpOpmVmheADKzKwAnEzNzArAydTMrACcTM1K\nmFTCw9f2A06myxFJK+cctyxmLJa3Wu+WaQ3LyXQ5IWkVYDdJO0o6AugrqVmx47IfK6+NStoYeFbS\nQUUOyfLgSfvLjwAWAX8GWgFdI2KhpLKIWFLc0CxXRISkfYEDgDeBSyQ1i4h7ixyaVcPJtJGTpEh8\nJektoDXwIrANMMyJtPRI+glwNXAM8DqwPTBA0ncR8a+iBmdVcjO/EStPpOnxKcBqwI7Av0ia+X3T\n9zqle4ZbEeUMNi0BXouIMRHxCfA48F/gCkl7Fy1Aq5aTaSNWIZEeB8yPiFnAs8AYYA9JdwN/ARYX\nLdDlXE4SXQ0gIuak5fek54uBqcDzwK8lrV2MOK16TqaNXDrwtDvQNyJekdQ0IuaS1HT+CXwGnBYR\nHxUzzuVZ2kfaGxgu6TpJuwFHAM0lPSnpeOBy4EFgLknft5UY95k2MrlN+1QzYB1gDeCNnPJVc/cP\nt+KRtDVJ8rwU2BTYl+Tv65fAuenxgUALYEtcCSpJ/ktpRCr0kXZPm4Nfk4zgXyxpw4hYJOlXwN2S\nWntSeHGlfdX3AJ9ExKPATcBkkkGnw4GrImIQsArwN+C4iPigWPFa1VwzbURyEukZJDWZMcBGwGXA\nmsD/JD0E7AwcHhGfFylUS0XEh5JuAC6V9HBEjJR0P0mLYjvgGWAWsADonfZ5WwnyEnyNQIUa6bbA\noIjYRdLNQEuSxBnpe4uBjyNiZhFDXm6V/11J2orkH7rXgVdJmvYXAWdExNOSWgCtnTyzw8k04yok\n0lbABiS10rnAXsCBEfF1OqjxQkR8WbxoDSAdbLoBGA5sCPwPGApsDVwJHB8RI4sXodWGm/kZl5NI\nTwS6A+cAewArR8Sm6XsnAH2AccWK0xKSmgCHkvR9PiNpe6A30CMi7khrpAuLGqTVigegMip34EjS\n4cAuwOUR8SkwGJgo6dq0//Q3QP+ImFecaA1AUk+gCfAd8AuAiBgDTAOOlLRiRNwSEc95YDB7nEwz\nqELT/qfA2iTPcTdJLxlBMi8xSAYyjoiIqcWIdXkmaS1JO6bH3YB/kEx9up9kDun+6aVTgfnASuX3\nhvvfMsd9phmWNu2PJqnlXA90BvbzBPzik9QU6A80J5nu9BBwX0Rck/4D+Etg1/TyjsBFEfFwUYK1\ngnAyzShJewHnAb+KiFmSVgAGkCxgcmj6lJMVQc6IfVdgCHA7yUpdBwN7RcTb6dqyLUn+AfwgIqZV\n8sCFZYib+RlRoY90RWA9knmI3QEi4jvgd8BrwO2S/HdbBJJ+BpwvqU1EvAT8FvgVyUpdtwGDJXWI\niK8iYk5EjIiIaeCmfda5ZpoBFfpIVwW+S6c7nUQyP/GaiBiRvt8MWM010+KQNAA4m2Slp/7AxyTJ\ntDXwKLASoUepAAAFr0lEQVQPsC1wSkS8W6w4rfA8NSoDchLpuSRL6K0jaSDwAvAlcFq6gMmTEbGQ\nZI6pNaD0978IuARoQ9J8/zUwA2hLMrj0HXAjyaOhbQAn00bEybSEpQtgNAH+D9gK6AvsRjIZfxeS\nPrcHSWo9x0h6FvjazcWGlT5ff5CkCRExJn3yrCfwHsmc0V+QzCXdJCL2kvS7dFk9a0Tcr1aiJO1J\nsrDFxiSrBa0JvB4R8yLifpIFns8nWVHoVuDEtB/OibThrUzy5NmAdH+t10j+gZufLl7yW5LVubaR\n1NmJtHFyzbQEpZO7byB5pv6ltOx1oLekbhExNiKGSxoNtI2IN4sZ7/IuIt6SdD5Ja+Fmkn/gviTZ\nu+mDiJgq6Rhg9Yh4o7rPsuzyAFQJknQ2sDgiri/vi0sHni4gaU18nL5+D+wcEe8VMVzLoWRH0dOA\nD4HDSJ5uOrV89XxrvNzMLyE505/WI2nWAyxWsoPoF8BVwDxgE5KBqD5OpKUlIl4DLibZGuZ1YG+S\nifvWyLlmWoIk7QJcCFwQEePTOaNlaQ31VGAY8E46t9RKmKQuETGp2HFY/XPNtDSNJdk87RBJW0fE\nkjSRHgocSzJi70RawsofmihPpF64pPFzzbREpVuOHEfy/PbLJNuPHAQcFBGvFDM2M/sxJ9MSJqk5\nyYLBuwEfAE9HxP8VNyozq4yTqZlZAbjP1MysAJxMzcwKwMnUzKwAnEzNzArAydTMrACcTM3MCsDJ\n1OqVpPnpnz+RNLSGa8+QtFJ111RyT09Jj+VbXuGaoyTdsIzf97ak1ZflHls+OJnaMlvG/aUCICI+\niIi+NVx7JsnaoMuqqsnS+UyiXtaJ1p6YbZVyMrWlJHWQ9KqkuyRNlzS0vKaY1sgGSXqZZFX5n0t6\nQtJLkkZJ2jC9bl1JYyRNlnR5hc+emh6XSbpK0lRJkySdIuk04KfA05L+l163e/pZL0u6P93RE0l7\npnG+DByYx8/VNf2c8ZKel9Qx5+11JD0t6XVJF+fc00/SWEkTJP0159l6pe+vLOk/kiZKmiLp4Nr/\n5q1RiAi//CIiADoAS4Du6fmtwNnp8dvAuTnXjgDWT4+3Bf6XHj8C9EuPTwbm5Xz2lPT4JGAo3z+B\n1zr98y2SzQAh2SNpFNA8PT8fuAhYkWTvpJ+n5fcDj1bys/QsLyfZqaAsPd4VeDA9PgqYTbIq/krA\nVJLtYTYm2fyuSXrdjcAROb+H1UmS+N9zvq9lsf/+/CruyyvtW0XvRsSL6fFdJAsdX5Oe3w8gaRVg\ne+CBnBpbs/TPHnxfW7wTGFTJd+wK/DUiyrsAPk/Llb4g2cK6EzA6/Y5mJBsIbgy8FRFv5cT46xp+\nptbAP9MaafDDHSaGl3+/pH8BOwCLSdZEeCn97pVIFnvONRW4Ot3Y8L8R8XwNMVgj52RqNcntI/wy\n/bMM+Cwitqri+vJ76rLsnIBhEdHvB4XSFrX43MuBkRFxoKQOwNM57+X+fMo5vyMiflfVB0bEDElb\nkWyUN0DSiIgYsIxxWSPiPlOraB1J3dLjw4HnKl4QEfOBtyUdVF4mafP0cDTJdh0A/SremxoOnCip\nSXrvamn5PKBVevwi0EPS+uk1K6c1y9eADpLWS687jJqtStKcBzimwnu9JLVOV+jaP41/JEm/8Jrl\n8UlaJ/cmST8hWVf2HpIdECr7h8WWI06mVtHrwCmSppM0j/+Wllccxe4HHJcOIL0C9EnLz0zvnwz8\npIrvuIVkG+QpkibyfUL8B/CkpP9FxMckie/e9LPGABtFxLfAicDj6QBUPnsr/REYJGk8P/5vfhzw\nEDAJeCAiJkTEqyT9s8PS7x4GtKvwe+gMjEvjvxhwrXQ55yX4bKm0CfyfiOhc7FjMssY1U6vI/7qa\n1YJrpmZmBeCaqZlZATiZmpkVgJOpmVkBOJmamRWAk6mZWQE4mZqZFcD/A187O8Dk0LlcAAAAAElF\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9c80a26f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Label  Gold  Guess  Precision    Recall        F1\n",
      "0      0   326    333   0.912913  0.932515  0.922610\n",
      "1      1   164    157   0.859873  0.823171  0.841121\n",
      "2  [All]   490    490   0.895918  0.895918  0.895918\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from fleiss_kappa import fleiss_kappa\n",
    "\n",
    "import csv\n",
    "import fce_api as fd\n",
    "import itertools\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "import settings\n",
    "\n",
    "\n",
    "def get_annotations(golden=defaultdict(list)):\n",
    "    \"\"\"\n",
    "    Retrieves all annotations per sentence from AMT batch\n",
    "    Args:\n",
    "        golden: expert annotation per sentence: opt\n",
    "    Returns:\n",
    "        result_annotations: dict of the form sentence-> annotations\n",
    "    \"\"\"\n",
    "    result_annotations = defaultdict(list)\n",
    "    with open(settings.AMT_FILE) as file:\n",
    "        csv_reader = csv.DictReader(file)\n",
    "        for row in csv_reader:\n",
    "            sentence = row['Input.sentence']\n",
    "            answer = json.loads(row['Answer.ChosenWord'])\n",
    "            for annotation in answer['selectedTokens']:\n",
    "                result_annotations[sentence].append(annotation['start'])\n",
    "        for key in result_annotations.keys():\n",
    "            for error_index in golden[key]:\n",
    "                result_annotations[key].append(error_index)\n",
    "    return result_annotations\n",
    "\n",
    "\n",
    "def create_confusion_matrix(data, predictions):\n",
    "    \"\"\"\n",
    "    Produces a confusion matrix in a form of a dictionary from (gold_label,guess_label)` pairs to counts.\n",
    "    Args:\n",
    "        data: list containing the gold labels.\n",
    "        predictions: list containing the prediction labels\n",
    "\n",
    "    Returns:\n",
    "        confusion matrix in form of dictionary with counts for (gold_label, guess_label)\n",
    "    \"\"\"\n",
    "    confusion = defaultdict(int)\n",
    "    for y_gold, y_guess in zip(data, predictions):\n",
    "        confusion[(y_gold, y_guess)] += 1\n",
    "    return confusion\n",
    "\n",
    "\n",
    "def plot_confusion_matrix_dict(matrix_dict, classes=None, rotation=45, outside_label=''):\n",
    "    \"\"\"\n",
    "    Plots the confusion matrix\n",
    "    Args:\n",
    "        matrix_dict: the dict of confusion matrix - output of create_confusion_matrix\n",
    "        classes: list containing the classes for the category labels, if empty, whole numbering will be used for\n",
    "        category names\n",
    "        rotation: the degree orientation of the axis labels\n",
    "        outside_label: the label to disregard -  excluded by default\n",
    "    \"\"\"\n",
    "    labels = set([y for y, _ in matrix_dict.keys()] + [y for _, y in matrix_dict.keys()])\n",
    "    sorted_labels = sorted(labels, key=lambda x: -x)\n",
    "    matrix = np.zeros((len(sorted_labels), len(sorted_labels)))\n",
    "    for i1, y1 in enumerate(sorted_labels):\n",
    "        for i2, y2 in enumerate(sorted_labels):\n",
    "            if y1 != outside_label or y2 != outside_label:\n",
    "                matrix[i1, i2] = matrix_dict[y1, y2]\n",
    "\n",
    "    threshold = matrix.max() / 2.\n",
    "    for i, j in itertools.product(range(matrix.shape[0]), range(matrix.shape[1])):\n",
    "        plt.text(j, i, int(matrix[i, j]),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if matrix[i, j] > threshold else \"black\")\n",
    "\n",
    "    plt.imshow(matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.colorbar()\n",
    "    if classes is None:\n",
    "        classes = sorted_labels\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=rotation)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    plt.xlabel('predicted labels')\n",
    "    plt.ylabel('gold labels')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def full_evaluation_table(confusion_matrix, classes=list()):\n",
    "    \"\"\"\n",
    "    Produces a pandas data-frame with Precision, F1 and Recall for all labels.\n",
    "    Args:\n",
    "        confusion_matrix: the confusion matrix to calculate metrics from.\n",
    "        classes: the categories of the confusion matrix\n",
    "\n",
    "    Returns:\n",
    "        a pandas Dataframe with one row per gold label, and one more row for the aggregate of all labels.\n",
    "    \"\"\"\n",
    "    labels = sorted(list({l for l, _ in confusion_matrix.keys()} | {l for _, l in confusion_matrix.keys()}))\n",
    "    if len(labels) == len(classes):\n",
    "        labels = classes\n",
    "    gold_counts = defaultdict(int)\n",
    "    guess_counts = defaultdict(int)\n",
    "    for (gold_label, guess_label), count in confusion_matrix.items():\n",
    "        if gold_label != \"None\":\n",
    "            gold_counts[gold_label] += count\n",
    "            gold_counts[\"[All]\"] += count\n",
    "        if guess_label != \"None\":\n",
    "            guess_counts[guess_label] += count\n",
    "            guess_counts[\"[All]\"] += count\n",
    "\n",
    "    result_table = []\n",
    "    for label in labels:\n",
    "        if label != \"None\":\n",
    "            result_table.append((label, gold_counts[label], guess_counts[label], *evaluate(confusion_matrix, {label})))\n",
    "\n",
    "    result_table.append((\"[All]\", gold_counts[\"[All]\"], guess_counts[\"[All]\"], *evaluate(confusion_matrix)))\n",
    "    return pd.DataFrame(result_table, columns=('Label', 'Gold', 'Guess', 'Precision', 'Recall', 'F1'))\n",
    "\n",
    "\n",
    "def evaluate(conf_matrix, label_filter=None):\n",
    "    \"\"\"\n",
    "    Evaluate Precision, Recall and F1 based on a confusion matrix as produced by `create_confusion_matrix`.\n",
    "    Args:\n",
    "        conf_matrix: a confusion matrix in form of a dictionary from `(gold_label,guess_label)` pairs to counts.\n",
    "        label_filter: a set of gold labels to consider. If set to `None` all labels are considered.\n",
    "\n",
    "    Returns:\n",
    "        Precision, Recall, F1 triple.\n",
    "    \"\"\"\n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    for (gold, guess), count in conf_matrix.items():\n",
    "        if label_filter is None or gold in label_filter or guess in label_filter:\n",
    "            if gold == 'None' and guess != gold:\n",
    "                fp += count\n",
    "            elif gold == 'None' and guess == gold:\n",
    "                tn += count\n",
    "            elif gold != 'None' and guess == gold:\n",
    "                tp += count\n",
    "            elif gold != 'None' and guess == 'None':\n",
    "                fn += count\n",
    "            else:  # both gold and guess are not-None, but different\n",
    "                fp += count if label_filter is None or guess in label_filter else 0\n",
    "                fn += count if label_filter is None or gold in label_filter else 0\n",
    "    prec = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    f1 = 2 * prec * recall / (prec + recall) if prec * recall > 0 else 0.0\n",
    "    return prec, recall, f1\n",
    "\n",
    "\n",
    "def extract_sentences_with_errors():\n",
    "    \"\"\"\n",
    "    Extracts AMT sentences along with their errors to a file.\n",
    "    \"\"\"\n",
    "    with open(settings.TRAINING_DATA_FILE, 'r') as file:\n",
    "        # read the lines\n",
    "        readlines = file.readlines()\n",
    "        with open(settings.AMT_SENTENCE_BATCH, 'r') as amt_batch:\n",
    "            csv_reader = csv.DictReader(amt_batch)\n",
    "            with open(settings.AMT_FCE_M2, 'w+') as destination:\n",
    "                for row in csv_reader:\n",
    "                    sentence = row['sentence']\n",
    "                    i = 0\n",
    "                    while i < len(readlines):\n",
    "                        if sentence == readlines[i][2:-1]:\n",
    "                            destination.write(readlines[i])\n",
    "                            i += 1\n",
    "                            while readlines[i][0] != 'S' and i < len(readlines):\n",
    "                                destination.writelines(readlines[i])\n",
    "                                i += 1\n",
    "                        else:\n",
    "                            i += 1\n",
    "\n",
    "\n",
    "# compare the annotations with gold\n",
    "def compare_annotations(gold_sentences, annotation_labels):\n",
    "    \"\"\"\n",
    "    Produces gold and annotation error detection labels from given annotations and gold data\n",
    "    Args:\n",
    "        gold_sentences: a list  of tuples containing the sentences and the related gold error annotations.\n",
    "        annotation_labels: labels from the annotation representing the start index of the error\n",
    "\n",
    "    Returns:\n",
    "        gold and predicted labels\n",
    "    \"\"\"\n",
    "    gold = []\n",
    "    predicted = []\n",
    "\n",
    "    for sentence in gold_sentences:\n",
    "        labels = annotation_labels[sentence[0][1:]]\n",
    "        for label in labels:\n",
    "            counted = 0\n",
    "            error_spans = sentence[1]\n",
    "            if label == - 2 and len(error_spans) == 0:\n",
    "                gold.append(0)\n",
    "                predicted.append(0)\n",
    "                counted = 1\n",
    "            if label == -2 and len(error_spans) > 0:\n",
    "                gold.append(1)\n",
    "                predicted.append(0)\n",
    "                counted = 1\n",
    "            for error_span in error_spans:\n",
    "                if error_span[0] <= int(label) < error_span[1]:\n",
    "                    gold.append(1)\n",
    "                    predicted.append(1)\n",
    "                    counted = 1\n",
    "                if label == str(error_span[0]) and label == str(error_span[1]):\n",
    "                    gold.append(1)\n",
    "                    predicted.append(1)\n",
    "                    counted = 1\n",
    "            if counted == 0:\n",
    "                gold.append(0)\n",
    "                predicted.append(1)\n",
    "    return gold, predicted\n",
    "\n",
    "\n",
    "def create_agreement_dictionary(annotations, gold_labels, shadow=False):\n",
    "    \"\"\"\n",
    "    Produces the agreement dictionary used for inter-rater agreement and accuracy scores\n",
    "    sentence -> (worker_id, annotations)\n",
    "    Args:\n",
    "        annotations: the annotations for each sentence\n",
    "        gold_labels: the golden annotations\n",
    "        shadow: apply no labeled annotations\n",
    "    Returns:\n",
    "        agreement_dictionary: a dictionary for inter-rater agreement\n",
    "    \"\"\"\n",
    "    agreement_dictionary = defaultdict(list)\n",
    "    with open(settings.AMT_FILE) as file:\n",
    "        csv_reader = csv.DictReader(file)\n",
    "        for row in csv_reader:\n",
    "            sentence = row['Input.sentence']\n",
    "            worker_id = row['WorkerId']\n",
    "            answer = json.loads(row['Answer.ChosenWord'])\n",
    "            worker_annotations = [x['start'] for x in answer['selectedTokens']]\n",
    "            annotations_for_sentence = list(set(annotations[sentence]))\n",
    "            tokens = re.split(r'(\\s+)', sentence)\n",
    "            shadow_annotations = []\n",
    "            if shadow:\n",
    "                shadow_annotations = [0] * (len(tokens) + 2 - len(annotations_for_sentence))\n",
    "            explicit_annotations = [1 if x in worker_annotations else 0 for x in annotations_for_sentence]\n",
    "            agreement_dictionary[sentence].append((worker_id, explicit_annotations + shadow_annotations))\n",
    "    for key in agreement_dictionary.keys():\n",
    "        annotations_for_sentence = list(set(annotations[key]))\n",
    "        tokens = re.split(r'(\\s+)', key)\n",
    "        shadow_annotations = []\n",
    "        if shadow:\n",
    "            shadow_annotations = [0] * (len(tokens) + 2 - len(annotations_for_sentence))\n",
    "        explicit_annotations = [1 if x in gold_labels[key] else 0 for x in annotations_for_sentence]\n",
    "        agreement_dictionary[key].append(('expert', explicit_annotations + shadow_annotations))\n",
    "    return agreement_dictionary\n",
    "\n",
    "\n",
    "def create_binary_agreement_dictionary(gold_labels):\n",
    "    \"\"\"\n",
    "    Produces the binary agreement dictionary used for inter-rater agreement and accuracy scores\n",
    "    Binary puts only 1 annotation per sentence - without an error or with error\n",
    "    Args:\n",
    "        gold_labels: the golden annotations\n",
    "    Returns:\n",
    "        agreement_dictionary: a dictionary for inter-rater agreement\n",
    "    \"\"\"\n",
    "    agreement_dictionary = defaultdict(list)\n",
    "    with open(settings.AMT_FILE) as file:\n",
    "        csv_reader = csv.DictReader(file)\n",
    "        for row in csv_reader:\n",
    "            sentence = row['Input.sentence']\n",
    "            worker_id = row['WorkerId']\n",
    "            answer = json.loads(row['Answer.ChosenWord'])\n",
    "            if answer['selectedTokens'][0]['start'] == -2:\n",
    "                annotation = 0\n",
    "            else:\n",
    "                annotation = 1\n",
    "            agreement_dictionary[sentence].append((worker_id, [annotation]))\n",
    "    for key in agreement_dictionary.keys():\n",
    "        if gold_labels[key][0] == -2:\n",
    "            annotation = 0\n",
    "        else:\n",
    "            annotation = 1\n",
    "        agreement_dictionary[key].append(('expert', [annotation]))\n",
    "    return agreement_dictionary\n",
    "\n",
    "\n",
    "def create_gold_dict(data):\n",
    "    \"\"\"\n",
    "    Produces gold annotation labels in the same format as the selected tokens from the workers\n",
    "    Args:\n",
    "        data: list of the golden  data - fce_api standard (sentence, error_span) list\n",
    "\n",
    "    Returns:\n",
    "        selected tokens of the golden annotations\n",
    "    \"\"\"\n",
    "    gold_dict = defaultdict(list)\n",
    "    for sentence, error_spans in data:\n",
    "        if len(error_spans) == 0:\n",
    "            gold_dict[sentence[1:]].append(-2)\n",
    "        else:\n",
    "            for span in error_spans:\n",
    "                gold_dict[sentence[1:]].append(span[0])\n",
    "                for i in range(span[0] + 1, span[1]):\n",
    "                    gold_dict[sentence[1:]].append(i)\n",
    "    return gold_dict\n",
    "\n",
    "\n",
    "def calculate_agreement(agreement_dictionary):\n",
    "    \"\"\"\n",
    "    Calculates agreement averaging the accuracies from all possible combinations of turkers (Snow et al,. 2008)\n",
    "    Args:\n",
    "         agreement_dictionary: holding sentence annotation records - settings.RESPONSE_COUNT\n",
    "         from non-experts and one expert\n",
    "         sentence -> list of annotations (size settings.RESPONSE_COUNT + 1)\n",
    "\n",
    "    Returns:\n",
    "        The accuracies from combined agreement from one to nine non-experts with the expert\n",
    "    \"\"\"\n",
    "    sequence = list(range(settings.RESPONSE_COUNT))\n",
    "    combinations = []\n",
    "    for i in range(settings.RESPONSE_COUNT + 1):\n",
    "        combinations.append(list(itertools.combinations(sequence, i)))\n",
    "    accuracies = [0]\n",
    "    standard_deviations = [0]\n",
    "    for i in range(1, settings.RESPONSE_COUNT + 1):\n",
    "        current_combinations = combinations[i]\n",
    "        combination_accuracies = []\n",
    "        for combination in current_combinations:\n",
    "            correct = 0\n",
    "            incorrect = 0\n",
    "            for sentence in agreement_dictionary.keys():\n",
    "                expert_annotations = agreement_dictionary[sentence][-1][1]\n",
    "                chosen_annotations = [agreement_dictionary[sentence][x][1] for x in combination]\n",
    "                votes = np.sum(chosen_annotations, axis=0)\n",
    "                result_votes = [0] * len(votes)\n",
    "                for j in range(len(votes)):\n",
    "                    if votes[j] < len(chosen_annotations) / 2:\n",
    "                        result_votes[j] = 0\n",
    "                    elif votes[j] > len(chosen_annotations) / 2:\n",
    "                        result_votes[j] = 1\n",
    "                    else:\n",
    "                        result_votes[j] = 2\n",
    "                for j in range(len(votes)):\n",
    "                    if result_votes[j] == 2:\n",
    "                        correct += 0.5\n",
    "                        incorrect += 0.5\n",
    "                    elif expert_annotations[j] == result_votes[j]:\n",
    "                        correct += 1\n",
    "                    else:\n",
    "                        incorrect += 1\n",
    "            combination_accuracy = correct / (correct + incorrect)\n",
    "            combination_accuracies.append(combination_accuracy)\n",
    "        standard_deviation = np.std(combination_accuracies)\n",
    "        standard_deviations.append(standard_deviation)\n",
    "        accuracy = sum(combination_accuracies) / len(combination_accuracies)\n",
    "        accuracies.append(accuracy)\n",
    "    return accuracies, standard_deviations\n",
    "\n",
    "\n",
    "def calculate_agreement_random(agreement_dictionary):\n",
    "    \"\"\"\n",
    "    Calculates agreement averaging the accuracies from all possible combinations of turkers\n",
    "    random breaking ties\n",
    "    Args:\n",
    "         agreement_dictionary: holding sentence annotation records - settings.RESPONSE_COUNT\n",
    "         from non-experts and one expert\n",
    "         sentence -> list of annotations (size settings.RESPONSE_COUNT + 1)\n",
    "\n",
    "    Returns:\n",
    "        The accuracies from combined agreement from one to nine non-experts with the expert\n",
    "    \"\"\"\n",
    "    sequence = list(range(settings.RESPONSE_COUNT))\n",
    "    combinations = []\n",
    "    for i in range(settings.RESPONSE_COUNT + 1):\n",
    "        combinations.append(list(itertools.combinations(sequence, i)))\n",
    "    accuracies = [0]\n",
    "    standard_deviations = [0]\n",
    "    for i in range(1, settings.RESPONSE_COUNT + 1):\n",
    "        current_combinations = combinations[i]\n",
    "        combination_accuracies = []\n",
    "        for combination in current_combinations:\n",
    "            correct = 0\n",
    "            incorrect = 0\n",
    "            for sentence in agreement_dictionary.keys():\n",
    "                expert_annotations = agreement_dictionary[sentence][-1][1]\n",
    "                chosen_annotations = [agreement_dictionary[sentence][x][1] for x in combination]\n",
    "                votes = np.sum(chosen_annotations, axis=0)\n",
    "                chair = 0\n",
    "                if len(combination) % 2 == 0:\n",
    "                    chair = random.choice([x for x in list(combination)])\n",
    "                result_votes = [0] * len(votes)\n",
    "                for j in range(len(votes)):\n",
    "                    if votes[j] < len(chosen_annotations) / 2:\n",
    "                        result_votes[j] = 0\n",
    "                    elif votes[j] > len(chosen_annotations) / 2:\n",
    "                        result_votes[j] = 1\n",
    "                    else:\n",
    "                        result_votes[j] = agreement_dictionary[sentence][chair][1][j]\n",
    "                for j in range(len(votes)):\n",
    "                    if expert_annotations[j] == result_votes[j]:\n",
    "                        correct += 1\n",
    "                    else:\n",
    "                        incorrect += 1\n",
    "            combination_accuracy = correct / (correct + incorrect)\n",
    "            combination_accuracies.append(combination_accuracy)\n",
    "        standard_deviation = np.std(combination_accuracies)\n",
    "        standard_deviations.append(standard_deviation)\n",
    "        accuracy = sum(combination_accuracies) / len(combination_accuracies)\n",
    "        accuracies.append(accuracy)\n",
    "    return accuracies, standard_deviations\n",
    "\n",
    "\n",
    "def calculate_agreement_sum(agreement_dictionary):\n",
    "    \"\"\"\n",
    "    Calculates agreement over the sum (logical or) of annotations e.g [1, 0, 1] x [1, 0, 0] = [1, 0, 1]\n",
    "    Args:\n",
    "         agreement_dictionary: holding sentence annotation records - settings.RESPONSE_COUNT\n",
    "         from non-experts and one expert\n",
    "         sentence -> list of annotations (size settings.RESPONSE_COUNT + 1)\n",
    "\n",
    "    Returns:\n",
    "        The accuracies from combined agreement from one to nine non-experts with the expert\n",
    "    \"\"\"\n",
    "    sequence = list(range(settings.RESPONSE_COUNT))\n",
    "    combinations = []\n",
    "    for i in range(settings.RESPONSE_COUNT + 1):\n",
    "        combinations.append(list(itertools.combinations(sequence, i)))\n",
    "    accuracies = [0]\n",
    "    standard_deviations = [0]\n",
    "    for i in range(1, settings.RESPONSE_COUNT + 1):\n",
    "        current_combinations = combinations[i]\n",
    "        combination_accuracies = []\n",
    "        for combination in current_combinations:\n",
    "            correct = 0\n",
    "            incorrect = 0\n",
    "            for sentence in agreement_dictionary.keys():\n",
    "                expert_annotations = agreement_dictionary[sentence][-1][1]\n",
    "                chosen_annotations = [agreement_dictionary[sentence][x][1] for x in combination]\n",
    "                votes = np.sum(chosen_annotations, axis=0)\n",
    "                result_votes = [0] * len(votes)\n",
    "                for j in range(len(votes)):\n",
    "                    if votes[j] > 0:\n",
    "                        result_votes[j] = 1\n",
    "                    else:\n",
    "                        result_votes[j] = 0\n",
    "                for j in range(len(result_votes)):\n",
    "                    if expert_annotations[j] == result_votes[j]:\n",
    "                        correct += 1\n",
    "                    else:\n",
    "                        incorrect += 1\n",
    "            combination_accuracy = correct / (correct + incorrect)\n",
    "            combination_accuracies.append(combination_accuracy)\n",
    "        standard_deviation = np.std(combination_accuracies)\n",
    "        standard_deviations.append(standard_deviation)\n",
    "        accuracy = sum(combination_accuracies) / len(combination_accuracies)\n",
    "        accuracies.append(accuracy)\n",
    "    return accuracies, standard_deviations\n",
    "\n",
    "\n",
    "def calculate_agreement_incremental(agreement_dictionary):\n",
    "    \"\"\"\n",
    "    Calculates the agreement by incrementally adding additional turker rather than taking all the combinations of\n",
    "    turkers\n",
    "    Args:\n",
    "         agreement_dictionary: holding sentence annotation records - 9 from non-experts and 1 expert\n",
    "         sentence -> list of annotations (size settings.RESPONSE_COUNT + 1)\n",
    "\n",
    "    Returns:\n",
    "        The accuracies from combined agreement from one to nine non-experts with the expert\n",
    "    \"\"\"\n",
    "    combinations = []\n",
    "    for i in range(settings.RESPONSE_COUNT + 1):\n",
    "        combinations.append([tuple(range(i))])\n",
    "    print(combinations)\n",
    "    accuracies = [0]\n",
    "    for i in range(1, settings.RESPONSE_COUNT + 1):\n",
    "        current_combinations = combinations[i]\n",
    "        combination_accuracies = []\n",
    "        for combination in current_combinations:\n",
    "            correct = 0\n",
    "            incorrect = 0\n",
    "            for sentence in agreement_dictionary.keys():\n",
    "                expert_annotations = agreement_dictionary[sentence][-1][1]\n",
    "                chosen_annotations = [agreement_dictionary[sentence][x][1] for x in combination]\n",
    "                votes = np.sum(chosen_annotations, axis=0)\n",
    "                chair = 0\n",
    "                if len(combination) > 0 and len(combination) % 2 == 0:\n",
    "                    chair = combination[-1]\n",
    "                result_votes = [0] * len(votes)\n",
    "                for j in range(len(votes)):\n",
    "                    if votes[j] < len(chosen_annotations) / 2:\n",
    "                        result_votes[j] = 0\n",
    "                    elif votes[j] > len(chosen_annotations) / 2:\n",
    "                        result_votes[j] = 1\n",
    "                    else:\n",
    "                        result_votes[j] = agreement_dictionary[sentence][chair][1][j]\n",
    "                for j in range(len(votes)):\n",
    "                    if expert_annotations[j] == result_votes[j]:\n",
    "                        correct += 1\n",
    "                    else:\n",
    "                        incorrect += 1\n",
    "            combination_accuracy = correct / (correct + incorrect)\n",
    "            combination_accuracies.append(combination_accuracy)\n",
    "        accuracy = sum(combination_accuracies) / len(combination_accuracies)\n",
    "        accuracies.append(accuracy)\n",
    "    return accuracies\n",
    "\n",
    "\n",
    "def calculate_agreement_second(agreement_dictionary):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "         agreement_dictionary: holding sentence annotation records - 9 from non-experts and 1 expert\n",
    "         sentence -> list of annotations (size settings.RESPONSE_COUNT + 1)\n",
    "\n",
    "    Returns:\n",
    "        The accuracies from combined agreement from one to nine non-experts with the expert\n",
    "    \"\"\"\n",
    "    sequence = list(range(settings.RESPONSE_COUNT))\n",
    "    combinations = []\n",
    "    for i in range(settings.RESPONSE_COUNT + 1):\n",
    "        combinations.append(list(itertools.combinations(sequence, i)))\n",
    "    accuracies = [0]\n",
    "    for i in range(1, settings.RESPONSE_COUNT + 1):\n",
    "        current_combinations = combinations[i]\n",
    "        sentence_votes = defaultdict(list)\n",
    "        correct = 0\n",
    "        incorrect = 0\n",
    "        for combination in current_combinations:\n",
    "            for sentence in agreement_dictionary.keys():\n",
    "                chosen_annotations = [agreement_dictionary[sentence][x][1] for x in combination]\n",
    "                votes = np.sum(chosen_annotations, axis=0)\n",
    "                for j in range(len(votes)):\n",
    "                    votes[j] = votes[j] / len(combination)\n",
    "                sentence_votes[sentence].append(votes)\n",
    "        for key in sentence_votes.keys():\n",
    "            result_votes = [0] * len(sentence_votes[key][0])\n",
    "            expert_annotations = agreement_dictionary[key][-1][1]\n",
    "            for votes in sentence_votes[key]:\n",
    "                for k in range(len(votes)):\n",
    "                    result_votes[k] += votes[k]\n",
    "            for j in range(len(result_votes)):\n",
    "                aggregated_vote = result_votes[j] / len(result_votes)\n",
    "                if aggregated_vote < 0.5:\n",
    "                    result_votes[j] = 0\n",
    "                elif aggregated_vote > 0.5:\n",
    "                    result_votes[j] = 1\n",
    "                else:\n",
    "                    result_votes[j] = 0\n",
    "                if result_votes[j] == expert_annotations[j]:\n",
    "                    correct += 1\n",
    "                else:\n",
    "                    incorrect += 1\n",
    "        accuracy = correct / (correct + incorrect)\n",
    "        accuracies.append(accuracy)\n",
    "    return accuracies\n",
    "\n",
    "\n",
    "def extract_information_per_turker():\n",
    "    \"\"\"\n",
    "    Extracts dictionary with turker's details\n",
    "    Returns:\n",
    "        user_information: dictionary with user details\n",
    "    \"\"\"\n",
    "    user_information = {}\n",
    "    with open(settings.AMT_FILE) as file:\n",
    "        csv_reader = csv.DictReader(file)\n",
    "        for row in csv_reader:\n",
    "            worker_id = row['WorkerId']\n",
    "            location_info = json.loads(row['Answer.ClientLocation'])\n",
    "            quality_info = json.loads(row['Answer.CountTries'])\n",
    "            if worker_id not in user_information:\n",
    "                if 'backUpLocation' in location_info:\n",
    "                    user_information[worker_id] = location_info['backUpLocation']\n",
    "                elif 'latitude' in location_info and 'longitude' in location_info:\n",
    "                    user_information[worker_id] = {'latitude': location_info['latitude'],\n",
    "                                                   'longitude': location_info['longitude']}\n",
    "                else:\n",
    "                    user_information[worker_id] = {'latitude': 'unknown', 'longitude': 'unknown'}\n",
    "                user_information[worker_id]['countTries'] = 0\n",
    "                user_information[worker_id]['tasks'] = 0\n",
    "            user_information[worker_id]['countTries'] += quality_info['countTries']\n",
    "            user_information[worker_id]['tasks'] += 1\n",
    "            user_information[worker_id]['triesPerTask'] = user_information[worker_id]['countTries'] / \\\n",
    "                                                          user_information[worker_id]['tasks']\n",
    "    return user_information\n",
    "\n",
    "\n",
    "def extract_coordinates(user_information):\n",
    "    \"\"\"\n",
    "    Extracts the turker's coordinates: (latitude, longitude)\n",
    "    Args:\n",
    "        user_information: dict with the user information of the turkers (returned from @extract_information_per_turker\n",
    "    Returns:\n",
    "        locations: latitude, longitude) pairs\n",
    "    \"\"\"\n",
    "    coordinates = []\n",
    "    for turker_id in user_information.keys():\n",
    "        latitude = user_information[turker_id]['latitude']\n",
    "        longitude = user_information[turker_id]['longitude']\n",
    "        coordinates.append((latitude, longitude))\n",
    "    return coordinates\n",
    "\n",
    "\n",
    "def extract_country_count(user_information):\n",
    "    \"\"\"\n",
    "    Extracts the turker's coordinates: (latitude, longitude)\n",
    "    Args:\n",
    "        user_information: dict with the user information of the turkers (returned from @extract_information_per_turker\n",
    "    Returns:\n",
    "        locations: latitude, longitude) pairs\n",
    "    \"\"\"\n",
    "    country_counts = defaultdict(int)\n",
    "    for turkerId in user_information.keys():\n",
    "        if 'country' in user_information[turkerId]:\n",
    "            country = user_information[turkerId]['country']\n",
    "            country_counts[country] += 1\n",
    "        else:\n",
    "            print(user_information[turkerId]['latitude'],' , ', user_information[turkerId]['longitude'])\n",
    "    return country_counts\n",
    "\n",
    "\n",
    "def agreement_minimum_hamming(agreement_dictionary, turker_accuracies):\n",
    "    \"\"\"\n",
    "    Calculates the best pseudo turker based on the closest response to the expert annotations.\n",
    "    Utilizing hamming distance.\n",
    "    Args:\n",
    "        agreement_dictionary: the agreement dictionary with turker IDs and annotations\n",
    "        turker_accuracies: the dictionary with the accuracies of the turkers\n",
    "    Return:\n",
    "        the accuracy with expert\n",
    "    \"\"\"\n",
    "    matched_turkers = {}\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    annotator_correlation_vector = []\n",
    "    gold_correlation_vector = []\n",
    "    for sentence in agreement_dictionary.keys():\n",
    "        expert_annotations = agreement_dictionary[sentence][-1][1]\n",
    "        min_distance = len(expert_annotations) + 1\n",
    "        min_worker_id = ''\n",
    "        min_index = -1\n",
    "        for i in range(settings.RESPONSE_COUNT):\n",
    "            distance = hamming(expert_annotations, agreement_dictionary[sentence][i][1])\n",
    "            worker_id = agreement_dictionary[sentence][i][0]\n",
    "            if distance < min_distance:\n",
    "                min_distance = distance\n",
    "                min_worker_id = worker_id\n",
    "                min_index = i\n",
    "        correct += len(expert_annotations) - min_distance\n",
    "        total += len(expert_annotations)\n",
    "        annotator_correlation_vector.extend(agreement_dictionary[sentence][min_index][1])\n",
    "        gold_correlation_vector.extend(expert_annotations)\n",
    "        worker_accuracy = turker_accuracies[min_worker_id][0][1]\n",
    "        if min_worker_id not in matched_turkers.keys():\n",
    "            matched_turkers[min_worker_id] = (worker_accuracy, 1)\n",
    "        else:\n",
    "            matched_turkers[min_worker_id] = (worker_accuracy, matched_turkers[min_worker_id][1] + 1)\n",
    "    accuracy = correct / total\n",
    "    return accuracy, matched_turkers, annotator_correlation_vector, gold_correlation_vector\n",
    "\n",
    "\n",
    "def hamming(correct, observed):\n",
    "    \"\"\"\n",
    "    Calculates hamming distance between correct code and observed code with possible errors\n",
    "    Args:\n",
    "        correct: the correct code as list (binary values)\n",
    "        observed: the given code as list (binary values)\n",
    "    Returns:\n",
    "        distance: the hamming distance between correct and observed code\n",
    "    \"\"\"\n",
    "    distance = 0\n",
    "    for i in range(len(correct)):\n",
    "        if correct[i] != observed[i]:\n",
    "            distance += 1\n",
    "    return distance\n",
    "\n",
    "\n",
    "def accuracy_per_turker(agreement_dictionary):\n",
    "    \"\"\"\n",
    "    Calculates accuracy for each participated turker - unique workId\n",
    "    Args:\n",
    "        agreement_dictionary: the agreement dictionary with turker IDs and annotations\n",
    "    Returns:\n",
    "        dictionary relating the turker with their accuracy and HITs completed\n",
    "    \"\"\"\n",
    "    turker_accuracies = defaultdict(list)\n",
    "    for sentence in agreement_dictionary:\n",
    "        expert_annotations = agreement_dictionary[sentence][-1][1]\n",
    "        for i in range(settings.RESPONSE_COUNT):\n",
    "            worker_id = agreement_dictionary[sentence][i][0]\n",
    "            if len(turker_accuracies[worker_id]) == 0:\n",
    "                turker_accuracies[worker_id].append((0, 0))\n",
    "                turker_accuracies[worker_id].append(0)\n",
    "            guesses = agreement_dictionary[sentence][i][1]\n",
    "            for j in range(len(guesses)):\n",
    "                if guesses[j] == 1:\n",
    "                    if guesses[j] == expert_annotations[j]:\n",
    "                        turker_accuracies[worker_id][0] = (turker_accuracies[worker_id][0][0] + 1, turker_accuracies[worker_id][0][1])\n",
    "                    turker_accuracies[worker_id][0] = (turker_accuracies[worker_id][0][0], turker_accuracies[worker_id][0][1] + 1)\n",
    "            turker_accuracies[worker_id][1] += 1\n",
    "\n",
    "    for worker_id in turker_accuracies.keys():\n",
    "        turker_accuracies[worker_id][0] = turker_accuracies[worker_id][0][0] / turker_accuracies[worker_id][0][1]\n",
    "        turker_accuracies[worker_id] = [(turker_accuracies[worker_id][1], turker_accuracies[worker_id][0])]\n",
    "    return turker_accuracies\n",
    "\n",
    "\n",
    "def run_display_confusion():\n",
    "    \"\"\"\n",
    "    Execute this function to display the confusion matrix and the precision recall table.\n",
    "    \"\"\"\n",
    "    gold_data = fd.extract_data(settings.AMT_FCE_M2)\n",
    "    annotations = get_annotations()\n",
    "    gold, predicted = compare_annotations(gold_data, annotations)\n",
    "    cm = create_confusion_matrix(gold, predicted)\n",
    "    plot_confusion_matrix_dict(cm, classes=['Error', 'No Error'])\n",
    "    precision_and_recall = full_evaluation_table(cm)\n",
    "    print(precision_and_recall)\n",
    "\n",
    "\n",
    "def plot_accuracies(accuracies, x_scope, y_scope, standard_deviations=[]):\n",
    "    \"\"\"\n",
    "    Plots the accuracies with their standard deviation\n",
    "    Args:\n",
    "        accuracies: agreement accuracies\n",
    "        standard_deviations:  the standard deviations corresponding to the accuracies\n",
    "        x_scope: the visible part of the x axis\n",
    "        y_scope: the visible part of the y axis\n",
    "    \"\"\"\n",
    "    plt.plot(accuracies)\n",
    "    x_s = list(range(settings.RESPONSE_COUNT + 1))\n",
    "    if len(standard_deviations) > 0:\n",
    "        plt.errorbar(x_s, accuracies, standard_deviations, linestyle='None', marker='^')\n",
    "    plt.xlabel('judgements')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.tight_layout()\n",
    "    axes = plt.gca()\n",
    "    axes.set_xlim(x_scope)\n",
    "    axes.set_ylim(y_scope)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_multiple_accuracies(accuracies, x_scope, y_scope, legend_labels=None, standard_deviations=None):\n",
    "    \"\"\"\n",
    "    Plots the accuracies with their standard deviation\n",
    "    Args:\n",
    "        accuracies: agreement accuracies\n",
    "        standard_deviations:  the standard deviations corresponding to the accuracies\n",
    "        x_scope: the visible part of the x axis\n",
    "        y_scope: the visible part of the y axis\n",
    "    \"\"\"\n",
    "\n",
    "    x_s = list(range(settings.RESPONSE_COUNT + 1))\n",
    "    if legend_labels is None:\n",
    "        legend_labels = [str(x) for x in range(len(accuracies[0]))]\n",
    "    legend_handles = []\n",
    "    for i in range(len(accuracies)):\n",
    "        legend_handles.append(plt.plot(accuracies[i], label=legend_labels[i]))\n",
    "        if len(standard_deviations[i]) > 0 and standard_deviations is not None:\n",
    "            plt.errorbar(x_s, accuracies[i], standard_deviations[i], linestyle='None', marker='^')\n",
    "    plt.xlabel('judgements')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.tight_layout()\n",
    "    plt.legend()\n",
    "    axes = plt.gca()\n",
    "    axes.set_xlim(x_scope)\n",
    "    axes.set_ylim(y_scope)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def run_agreement_without_golden(filename):\n",
    "    \"\"\"\n",
    "    Execute this function to get agreement without additional golden annotations.\n",
    "    \"\"\"\n",
    "    gold_data = fd.extract_data(settings.AMT_FCE_M2)\n",
    "    annotations = get_annotations()\n",
    "    gold_dict = create_gold_dict(gold_data)\n",
    "    agreement_dictionary = create_agreement_dictionary(annotations, gold_dict)\n",
    "    accuracies, standard_deviations = calculate_agreement(agreement_dictionary)\n",
    "    print(accuracies)\n",
    "    accuracies[0] = accuracies[1]  # pretty bug\n",
    "    print(standard_deviations)\n",
    "    plot_accuracies(accuracies, [0.95, settings.RESPONSE_COUNT], [0.6, 0.8], standard_deviations=standard_deviations)\n",
    "    save_accuracy_stdev(filename, accuracies, standard_deviations)\n",
    "\n",
    "\n",
    "def run_agreement_without_golden_random(filename):\n",
    "    \"\"\"\n",
    "    Execute this function to get agreement without additional golden annotations.\n",
    "    \"\"\"\n",
    "    gold_data = fd.extract_data(settings.AMT_FCE_M2)\n",
    "    annotations = get_annotations()\n",
    "    gold_dict = create_gold_dict(gold_data)\n",
    "    agreement_dictionary = create_agreement_dictionary(annotations, gold_dict)\n",
    "    accuracies, standard_deviations = calculate_agreement_random(agreement_dictionary)\n",
    "    print(accuracies)\n",
    "    accuracies[0] = accuracies[1]  # pretty bug\n",
    "    print(standard_deviations)\n",
    "    plot_accuracies(accuracies, [0.95, settings.RESPONSE_COUNT], [0.6, 0.8], standard_deviations=standard_deviations)\n",
    "    save_accuracy_stdev(filename, accuracies, standard_deviations)\n",
    "\n",
    "\n",
    "def run_agreement_with_golden(filename):\n",
    "    \"\"\"\n",
    "    Execute this function to get agreement with additional golden annotations.\n",
    "    \"\"\"\n",
    "    gold_data = fd.extract_data(settings.AMT_FCE_M2)\n",
    "    gold_dict = create_gold_dict(gold_data)\n",
    "    annotations = get_annotations(golden=gold_dict)\n",
    "    agreement_dictionary = create_agreement_dictionary(annotations, gold_dict)\n",
    "    accuracies, standard_deviations = calculate_agreement(agreement_dictionary)\n",
    "    print(accuracies)\n",
    "    accuracies[0] = accuracies[1]  # pretty bug\n",
    "    print(standard_deviations)\n",
    "    plot_accuracies(accuracies, [0.95, settings.RESPONSE_COUNT], [0.4, 0.7], standard_deviations=standard_deviations)\n",
    "    save_accuracy_stdev(filename, accuracies, standard_deviations)\n",
    "\n",
    "\n",
    "def run_agreement_with_golden_and_shadow(filename):\n",
    "    \"\"\"\n",
    "    Execute this function to get agreement without additional golden and bias (shadow) annotations.\n",
    "    \"\"\"\n",
    "    gold_data = fd.extract_data(settings.AMT_FCE_M2)\n",
    "    gold_dict = create_gold_dict(gold_data)\n",
    "    annotations = get_annotations(golden=gold_dict)\n",
    "    agreement_dictionary = create_agreement_dictionary(annotations, gold_dict, shadow=True)\n",
    "    accuracies, standard_deviations = calculate_agreement(agreement_dictionary)\n",
    "    print(accuracies)\n",
    "    accuracies[0] = accuracies[1]  # pretty bug\n",
    "    print(standard_deviations)\n",
    "    plot_accuracies(accuracies, [0.95, settings.RESPONSE_COUNT], [0.9, 0.95], standard_deviations=standard_deviations)\n",
    "    save_accuracy_stdev(filename, accuracies, standard_deviations)\n",
    "\n",
    "\n",
    "def run_binary_agreement():\n",
    "    \"\"\"\n",
    "    Execute this function to get binary agreement on sentences.\n",
    "    \"\"\"\n",
    "    gold_data = fd.extract_data(settings.AMT_FCE_M2)\n",
    "    gold_dict = create_gold_dict(gold_data)\n",
    "    agreement_dictionary = create_binary_agreement_dictionary(gold_dict)\n",
    "    accuracies, standard_deviations = calculate_agreement(agreement_dictionary)\n",
    "    print(accuracies)\n",
    "    plot_accuracies(accuracies, [1, settings.RESPONSE_COUNT], [0.4, 0.7], standard_deviations=standard_deviations)\n",
    "\n",
    "\n",
    "def run_agreement_with_golden_incremental():\n",
    "    \"\"\"\n",
    "    Execute this function to get incremental agreement on sentences with golden annotations.\n",
    "    \"\"\"\n",
    "    gold_data = fd.extract_data(settings.AMT_FCE_M2)\n",
    "    gold_dict = create_gold_dict(gold_data)\n",
    "    annotations = get_annotations()\n",
    "    agreement_dictionary = create_agreement_dictionary(annotations, gold_dict)\n",
    "    accuracies = calculate_agreement_incremental(agreement_dictionary)\n",
    "    print(accuracies)\n",
    "    plt.plot(accuracies)\n",
    "    plt.xlabel('judgements')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.tight_layout()\n",
    "    axes = plt.gca()\n",
    "    axes.set_xlim([1, settings.RESPONSE_COUNT])\n",
    "    axes.set_ylim([0.6, 0.8])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def run_create_location_csv():\n",
    "    \"\"\"\n",
    "    Records the location information for turkers in terms of latitude and longitude\n",
    "    \"\"\"\n",
    "    turker_details = extract_information_per_turker()\n",
    "    coordinates = extract_coordinates(turker_details)\n",
    "    print('number of turker Ids:', len(turker_details))\n",
    "    with open('locations.csv', 'w+') as location_file:\n",
    "        fieldnames = ['lat/lon', 'latitude', 'longitude']\n",
    "        csv_writer = csv.DictWriter(location_file,  lineterminator='\\n', fieldnames=fieldnames)\n",
    "        csv_writer.writeheader()\n",
    "        for coordinate in coordinates:\n",
    "            lat_lon = str(coordinate[0]) + ',' + str(coordinate[1])\n",
    "            row_dict = {\n",
    "                fieldnames[0]: lat_lon,\n",
    "                fieldnames[1]: coordinate[0],\n",
    "                fieldnames[2]: coordinate[1],\n",
    "            }\n",
    "            csv_writer.writerow(rowdict=row_dict)\n",
    "\n",
    "\n",
    "def run_create_country_count_csv():\n",
    "    \"\"\"\n",
    "    Computes and records the country distribution per turker\n",
    "    \"\"\"\n",
    "    turker_details = extract_information_per_turker()\n",
    "    country_count = extract_country_count(turker_details)\n",
    "    print('number of countries:', len(turker_details))\n",
    "    with open('country_count.csv', 'w+') as location_file:\n",
    "        fieldnames = ['Country', 'Count']\n",
    "        csv_writer = csv.DictWriter(location_file,  lineterminator='\\n', fieldnames=fieldnames)\n",
    "        csv_writer.writeheader()\n",
    "        for country in country_count.keys():\n",
    "            row_dict = {\n",
    "                fieldnames[0]: country,\n",
    "                fieldnames[1]: country_count[country]\n",
    "            }\n",
    "            csv_writer.writerow(rowdict=row_dict)\n",
    "\n",
    "\n",
    "def run_agreement_per_turker():\n",
    "    \"\"\"\n",
    "    Execute this to get plot of turker agreement related to completed HITs\n",
    "    \"\"\"\n",
    "    gold_data = fd.extract_data(settings.AMT_FCE_M2)\n",
    "    annotations = get_annotations()\n",
    "    gold_dict = create_gold_dict(gold_data)\n",
    "    agreement_dictionary = create_agreement_dictionary(annotations, gold_dict)\n",
    "    accuracies = accuracy_per_turker(agreement_dictionary)\n",
    "    print(accuracies)\n",
    "    high = [(x, y) for x, y in accuracies.items() if y[0][1] > 0.98]\n",
    "    print(high)\n",
    "    print((len(high)))\n",
    "    low = [(x, y) for x, y in accuracies.items() if y[0][1] < 0.01]\n",
    "    print(low)\n",
    "    print((len(low)))\n",
    "    values_list = [value[0] for value in accuracies.values()]\n",
    "    plt.scatter(*zip(*values_list), marker='P')\n",
    "    plt.title('Agreement of individual Turkers v # HITS')\n",
    "    plt.xlabel('Number of HITs completed')\n",
    "    plt.ylabel('Accuracy with expert')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def get_guessed_errors_counts():\n",
    "    \"\"\"\n",
    "    Gets  dictionary with the counts of guessed errors types\n",
    "    Returns:\n",
    "        guessed_error_dict: error_type->count\n",
    "    \"\"\"\n",
    "    gold_data = fd.extract_data(settings.AMT_FCE_M2)\n",
    "    annotations = get_annotations()\n",
    "    guessed_error_dict = defaultdict(int)\n",
    "    for sentence in gold_data:\n",
    "        annotations_sentence = list(set(annotations[sentence[0][1:]]))\n",
    "        if len(sentence[1]) < 1:\n",
    "            guessed_error_dict['no error'] += len([x for x in annotations_sentence if x == -2])\n",
    "        for span in sentence[1]:\n",
    "            for annotation in annotations_sentence:\n",
    "                if span[0] <= int(annotation) < int(span[1]):\n",
    "                    guessed_error_dict[span[2]] += 1\n",
    "                    break\n",
    "    return guessed_error_dict\n",
    "\n",
    "\n",
    "def run_create_error_count_csv():\n",
    "    error_dict, count_error_dict = fd.count_error_types(settings.AMT_FCE_M2)\n",
    "    count_tuples = count_error_dict.items()\n",
    "    count_tuples = sorted(count_tuples, key=lambda x: -x[1])\n",
    "    guessed_errors_counts = get_guessed_errors_counts()\n",
    "    with open('error_count.csv', 'w+') as location_file:\n",
    "        fieldnames = ['Error Type', 'Count', 'Guessed']\n",
    "        csv_writer = csv.DictWriter(location_file,  lineterminator='\\n', fieldnames=fieldnames)\n",
    "        csv_writer.writeheader()\n",
    "        for count_tuple in count_tuples:\n",
    "            csv_writer.writerow({\n",
    "                fieldnames[0]: count_tuple[0],\n",
    "                fieldnames[1]: count_tuple[1],\n",
    "                fieldnames[2]: guessed_errors_counts[count_tuple[0]]\n",
    "            })\n",
    "\n",
    "\n",
    "def run_best_pseudo_turker():\n",
    "    \"\"\"\n",
    "    Run the function to get the accuracy of the best pseudo turker\n",
    "    \"\"\"\n",
    "    gold_data = fd.extract_data(settings.AMT_FCE_M2)\n",
    "    annotations = get_annotations()\n",
    "    gold_dict = create_gold_dict(gold_data)\n",
    "    agreement_dictionary = create_agreement_dictionary(annotations, gold_dict)\n",
    "    accuracy, turker_set, best_agreement_vector, gold_agreement_vector = agreement_minimum_hamming(agreement_dictionary,\n",
    "                                                                                                   accuracy_per_turker(agreement_dictionary))\n",
    "    print(accuracy)\n",
    "    for key in turker_set.keys():\n",
    "        print(key, ' : (accuracy: ', turker_set[key][0], ', count: ', turker_set[key][1], ')')\n",
    "    print('Number of turkers: ', len(turker_set))\n",
    "    counts = sum([turker_set[key][1] for key in turker_set.keys()])\n",
    "    print('Counts: ', counts)\n",
    "    average_count = sum([turker_set[key][1] for key in turker_set.keys()]) / len(turker_set)\n",
    "    print('Average Count: ', average_count)\n",
    "    average_accuracy = sum([turker_set[key][0] for key in turker_set.keys()]) / len(turker_set)\n",
    "    print('Average Accuracy: ', average_accuracy)\n",
    "    pearson_r = scipy.stats.pearsonr(best_agreement_vector, gold_agreement_vector)\n",
    "    print('Pearson Correlation: ', pearson_r)\n",
    "    spearman_r = scipy.stats.spearmanr(best_agreement_vector, gold_agreement_vector)\n",
    "    print('Spearman Coefficient: ', spearman_r)\n",
    "    cohen_kappa = metrics.cohen_kappa_score(best_agreement_vector, gold_agreement_vector)\n",
    "    print(\"Cohen's Kappa: \", cohen_kappa)\n",
    "    cm = create_confusion_matrix(gold_agreement_vector, best_agreement_vector)\n",
    "    plot_confusion_matrix_dict(cm, classes=['Error', 'No Error'])\n",
    "    precision_and_recall = full_evaluation_table(cm)\n",
    "    print(precision_and_recall)\n",
    "    c = collections.Counter(best_agreement_)\n",
    "\n",
    "\n",
    "def calculate_agreement_stv(agreement_dictionary, turker_accuracies):\n",
    "    \"\"\"\n",
    "    Inter agreement with most accurate chair vote\n",
    "    Args:\n",
    "         agreement_dictionary: holding sentence annotation records - 9 from non-experts and 1 expert\n",
    "         sentence -> list of annotations (size settings.RESPONSE_COUNT + 1)\n",
    "         turker_accuracies: accuracy for each turker used for the chair vote\n",
    "    Returns:\n",
    "        The accuracies from combined agreement from one to nine non-experts with the expert\n",
    "    \"\"\"\n",
    "    sequence = list(range(settings.RESPONSE_COUNT))\n",
    "    combinations = []\n",
    "    for i in range(settings.RESPONSE_COUNT + 1):\n",
    "        combinations.append(list(itertools.combinations(sequence, i)))\n",
    "    print(combinations)\n",
    "    accuracies = [0]\n",
    "    standard_deviations = [0]\n",
    "    for i in range(1, settings.RESPONSE_COUNT + 1):\n",
    "        current_combinations = combinations[i]\n",
    "        combination_accuracies = []\n",
    "        for combination in current_combinations:\n",
    "            correct = 0\n",
    "            incorrect = 0\n",
    "            for sentence in agreement_dictionary.keys():\n",
    "                expert_annotations = agreement_dictionary[sentence][-1][1]\n",
    "                chosen_annotations = [agreement_dictionary[sentence][x][1] for x in combination]\n",
    "                votes = np.sum(chosen_annotations, axis=0)\n",
    "                chair = 0\n",
    "                if len(combination) > 0 and len(combination) % 2 == 0:\n",
    "                    max_accuracy = 0\n",
    "                    for judgement_index in combination:\n",
    "                        turker = agreement_dictionary[sentence][judgement_index][0]\n",
    "                        turker_accuracy = turker_accuracies[turker][0][1]\n",
    "                        if turker_accuracy > max_accuracy:\n",
    "                            max_accuracy = turker_accuracy\n",
    "                            chair = judgement_index\n",
    "                result_votes = [0] * len(votes)\n",
    "                for j in range(len(votes)):\n",
    "                    if votes[j] < len(chosen_annotations) / 2:\n",
    "                        result_votes[j] = 0\n",
    "                    elif votes[j] > len(chosen_annotations) / 2:\n",
    "                        result_votes[j] = 1\n",
    "                    else:\n",
    "                        result_votes[j] = agreement_dictionary[sentence][chair][1][j]\n",
    "                for j in range(len(votes)):\n",
    "                    if expert_annotations[j] == result_votes[j]:\n",
    "                        correct += 1\n",
    "                    else:\n",
    "                        incorrect += 1\n",
    "            combination_accuracy = correct / (correct + incorrect)\n",
    "            combination_accuracies.append(combination_accuracy)\n",
    "        standard_deviation = np.std(combination_accuracies)\n",
    "        standard_deviations.append(standard_deviation)\n",
    "        accuracy = sum(combination_accuracies) / len(combination_accuracies)\n",
    "        accuracies.append(accuracy)\n",
    "    return accuracies, standard_deviations\n",
    "\n",
    "\n",
    "def calculate_agreement_weighting_votes(agreement_dictionary, turker_accuracies):\n",
    "    \"\"\"\n",
    "    Inter agreement with most accurate chair vote\n",
    "    Args:\n",
    "         agreement_dictionary: holding sentence annotation records - 9 from non-experts and 1 expert\n",
    "         sentence -> list of annotations (size settings.RESPONSE_COUNT + 1)\n",
    "         turker_accuracies: accuracy for each turker used for the chair vote\n",
    "    Returns:\n",
    "        The accuracies from combined agreement from one to nine non-experts with the expert\n",
    "    \"\"\"\n",
    "    sequence = list(range(settings.RESPONSE_COUNT))\n",
    "    combinations = []\n",
    "    for i in range(settings.RESPONSE_COUNT + 1):\n",
    "        combinations.append(list(itertools.combinations(sequence, i)))\n",
    "    print(combinations)\n",
    "    accuracies = [0]\n",
    "    standard_deviations = [0]\n",
    "    for i in range(1, settings.RESPONSE_COUNT + 1):\n",
    "        current_combinations = combinations[i]\n",
    "        combination_accuracies = []\n",
    "        for combination in current_combinations:\n",
    "            correct = 0\n",
    "            incorrect = 0\n",
    "            for sentence in agreement_dictionary.keys():\n",
    "                expert_annotations = agreement_dictionary[sentence][-1][1]\n",
    "                chosen_annotations = [agreement_dictionary[sentence][x][1] for x in combination]\n",
    "                chair = 0\n",
    "                max_accuracy = 0\n",
    "                for judgement_index in combination:\n",
    "                    turker = agreement_dictionary[sentence][judgement_index][0]\n",
    "                    turker_accuracy = turker_accuracies[turker][0][1]\n",
    "                    if turker_accuracy > max_accuracy:\n",
    "                        max_accuracy = turker_accuracy\n",
    "                        chair = judgement_index\n",
    "                result_votes = [0] * len(chosen_annotations[0])\n",
    "                for j in range(len(chosen_annotations[0])):\n",
    "                    for judgement_index in combination:\n",
    "                        weighting_pairs = {0: 0, 1: 0}\n",
    "                        turker = agreement_dictionary[sentence][judgement_index][0]\n",
    "                        turker_accuracy = turker_accuracies[turker][0][1]\n",
    "                        weighting_pairs[agreement_dictionary[sentence][judgement_index][1][j]] += turker_accuracy\n",
    "                    if weighting_pairs[0] < weighting_pairs[1]:\n",
    "                        result_votes[j] = 1\n",
    "                    else:\n",
    "                        result_votes[j] = agreement_dictionary[sentence][chair][1][j]\n",
    "                for j in range(len(chosen_annotations[0])):\n",
    "                    if expert_annotations[j] == result_votes[j]:\n",
    "                        correct += 1\n",
    "                    else:\n",
    "                        incorrect += 1\n",
    "            combination_accuracy = correct / (correct + incorrect)\n",
    "            combination_accuracies.append(combination_accuracy)\n",
    "        standard_deviation = np.std(combination_accuracies)\n",
    "        standard_deviations.append(standard_deviation)\n",
    "        accuracy = sum(combination_accuracies) / len(combination_accuracies)\n",
    "        accuracies.append(accuracy)\n",
    "    return accuracies, standard_deviations\n",
    "\n",
    "\n",
    "def run_agreement_stv(filename):\n",
    "    gold_data = fd.extract_data(settings.AMT_FCE_M2)\n",
    "    gold_dict = create_gold_dict(gold_data)\n",
    "    annotations = get_annotations(golden=gold_dict)\n",
    "    agreement_dictionary = create_agreement_dictionary(annotations, gold_dict)\n",
    "    turker_accuracies = accuracy_per_turker(agreement_dictionary)\n",
    "    accuracies, standard_deviations = calculate_agreement_stv(agreement_dictionary, turker_accuracies)\n",
    "    accuracies[0] = accuracies[1]\n",
    "    print(accuracies)\n",
    "    plot_accuracies(accuracies, [0.95, settings.RESPONSE_COUNT], [0.4, 0.7])\n",
    "    save_accuracy_stdev(filename, accuracies, standard_deviations)\n",
    "\n",
    "\n",
    "def run_agreement_sum(filename):\n",
    "    gold_data = fd.extract_data(settings.AMT_FCE_M2)\n",
    "    gold_dict = create_gold_dict(gold_data)\n",
    "    annotations = get_annotations(golden=gold_dict)\n",
    "    agreement_dictionary = create_agreement_dictionary(annotations, gold_dict)\n",
    "    accuracies, standard_deviations = calculate_agreement_sum(agreement_dictionary)\n",
    "    accuracies[0] = accuracies[1]\n",
    "    print(accuracies)\n",
    "    plot_accuracies(accuracies, [0.95, settings.RESPONSE_COUNT], [0.1, 0.7], standard_deviations=standard_deviations)\n",
    "    save_accuracy_stdev(filename, accuracies, standard_deviations)\n",
    "\n",
    "\n",
    "def save_accuracy_stdev(filename, accuracies, stdev):\n",
    "    with open(filename, 'w+') as location_file:\n",
    "        fieldnames = ['Judgements', 'Accuracy', 'SD']\n",
    "        csv_writer = csv.DictWriter(location_file,  lineterminator='\\n', fieldnames=fieldnames)\n",
    "        csv_writer.writeheader()\n",
    "        for i in range(1, len(accuracies)):\n",
    "            csv_writer.writerow({\n",
    "                fieldnames[0]: i,\n",
    "                fieldnames[1]: accuracies[i],\n",
    "                fieldnames[2]: stdev[i]\n",
    "            })\n",
    "\n",
    "\n",
    "def calculate_fleiss_kappa(agreement_dictionary):\n",
    "    \"\"\"\n",
    "       Calculates the Fleiss Kappa over annotations\n",
    "       Args:\n",
    "           agreement_dictionary: the dictionary with the annotations used in agreement\n",
    "       Return:\n",
    "           Fleiss kappa of the annotations\n",
    "    \"\"\"\n",
    "    annotation_count = 1\n",
    "    fleiss_input = []\n",
    "    for key in agreement_dictionary.keys():\n",
    "        for i in range(len(agreement_dictionary[key][0][1])):\n",
    "            for j in range(len(agreement_dictionary[key]) - 1):\n",
    "                fleiss_input.append((annotation_count, agreement_dictionary[key][j][1][i]))\n",
    "            annotation_count += 1\n",
    "    kappa = fleiss_kappa(fleiss_input, 9)\n",
    "    return kappa\n",
    "\n",
    "\n",
    "def run_fleiss_kappa():\n",
    "    gold_data = fd.extract_data(settings.AMT_FCE_M2)\n",
    "    gold_dict = create_gold_dict(gold_data)\n",
    "    annotations = get_annotations(golden=gold_dict)\n",
    "    agreement_dictionary = create_agreement_dictionary(annotations, gold_dict)\n",
    "    f_kappa = calculate_fleiss_kappa(agreement_dictionary)\n",
    "    print('Fleiss Kappa: ', f_kappa)\n",
    "\n",
    "def run_test_with_count_tries():\n",
    "    gold_data = fd.extract_data(settings.AMT_FCE_M2)\n",
    "    gold_dict = create_gold_dict(gold_data)\n",
    "    annotations = get_annotations(golden=gold_dict)\n",
    "    agreement_dictionary = create_agreement_dictionary(annotations, gold_dict)\n",
    "    turker_accuracies = accuracy_per_turker(agreement_dictionary)\n",
    "    information_dict = extract_information_per_turker()\n",
    "    tries_vs_accuracies = []\n",
    "    for key in turker_accuracies.keys():\n",
    "        turker_accuracy = turker_accuracies[key][0][1]\n",
    "        turker_tries = information_dict[key]['triesPerTask']\n",
    "        try_vs_accuracy = (turker_accuracy, turker_tries)\n",
    "        tries_vs_accuracies.append(try_vs_accuracy)\n",
    "    tries_vs_accuracies.sort(key=lambda x: -x[0])\n",
    "    cumulative_tries = 0\n",
    "    for i in range(len(tries_vs_accuracies)):\n",
    "        cumulative_tries += tries_vs_accuracies[i][1]\n",
    "        tries_vs_accuracies[i] = (i + 1, tries_vs_accuracies[i][1])\n",
    "    rank, tries = zip(*tries_vs_accuracies)\n",
    "    plt.scatter(rank, tries)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def run_stacked_plots():\n",
    "    gold_data = fd.extract_data(settings.AMT_FCE_M2)\n",
    "    gold_dict = create_gold_dict(gold_data)\n",
    "    annotations = get_annotations(golden=gold_dict)\n",
    "    agreement_dictionary = create_agreement_dictionary(annotations, gold_dict)\n",
    "    turker_accuracies = accuracy_per_turker(agreement_dictionary)\n",
    "    accuracies_set = [[x] for x in range(5)]\n",
    "    standard_deviations_set = [[x] for x in range(5)]\n",
    "    accuracies_set[0], standard_deviations_set[0] = calculate_agreement_sum(agreement_dictionary)\n",
    "    accuracies_set[1], standard_deviations_set[1] = calculate_agreement_stv(agreement_dictionary, turker_accuracies)\n",
    "    accuracies_set[2], standard_deviations_set[2] = calculate_agreement_random(agreement_dictionary)\n",
    "    accuracies_set[3], standard_deviations_set[3] = calculate_agreement(agreement_dictionary)\n",
    "    accuracies_set[4], standard_deviations_set[4] = calculate_agreement_weighting_votes(agreement_dictionary, turker_accuracies)\n",
    "    for i in range(len(accuracies_set)):\n",
    "        print('Accuracies ', i,' : ', accuracies_set[i])\n",
    "    for i in range(len(accuracies_set)):\n",
    "        accuracies_set[i][0] = accuracies_set[i][1]\n",
    "    plot_labels = ['over sum', 'most accurate STV', 'random vote', 'averaging (Snow et al.)', 'weighting votes']\n",
    "    plot_multiple_accuracies(accuracies_set,[1, settings.RESPONSE_COUNT], [0.2,  0.8],\n",
    "                             legend_labels=plot_labels, standard_deviations=standard_deviations_set)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #  run_agreement_without_golden('agreement_methods/accuracy_stdevs_without_golden_snow_et_al_1.csv')\n",
    "    #  run_agreement_with_golden('agreement_methods/accuracy_stdevs_with_golden_snow_et_al.csv')\n",
    "    #  run_agreement_with_golden_and_shadow('agreement_methods/accuracy_stdevs_with_golden_and_shadow_snow_et_al.csv')\n",
    "    #  run_agreement_stv('agreement_methods/accuracy_stdevs_stv.csv')\n",
    "    #  run_agreement_sum('agreement_methods/accuracy_stdevs_sum.csv')\n",
    "    run_best_pseudo_turker()\n",
    "    #run_stacked_plots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
