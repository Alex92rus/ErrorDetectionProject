{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feed_windows:  399610 sentences:  31218\n",
      "ready\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/numpy/core/numeric.py:301: FutureWarning: in the future, full([399610, 3], 0) will return an array of dtype('int64')\n",
      "  format(shape, fill_value, array(fill_value).dtype), FutureWarning)\n",
      "/opt/conda/lib/python3.5/site-packages/numpy/core/numeric.py:301: FutureWarning: in the future, full([399610, 2], 2) will return an array of dtype('int64')\n",
      "  format(shape, fill_value, array(fill_value).dtype), FutureWarning)\n",
      "/opt/conda/lib/python3.5/site-packages/numpy/core/numeric.py:301: FutureWarning: in the future, full(3, 0) will return an array of dtype('int64')\n",
      "  format(shape, fill_value, array(fill_value).dtype), FutureWarning)\n",
      "/opt/conda/lib/python3.5/site-packages/numpy/core/numeric.py:301: FutureWarning: in the future, full(2, 0) will return an array of dtype('int64')\n",
      "  format(shape, fill_value, array(fill_value).dtype), FutureWarning)\n",
      "/opt/conda/lib/python3.5/site-packages/numpy/core/numeric.py:301: FutureWarning: in the future, full(1, 0) will return an array of dtype('int64')\n",
      "  format(shape, fill_value, array(fill_value).dtype), FutureWarning)\n",
      "/opt/conda/lib/python3.5/site-packages/numpy/core/numeric.py:301: FutureWarning: in the future, full(0, 0) will return an array of dtype('int64')\n",
      "  format(shape, fill_value, array(fill_value).dtype), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399610\n",
      "0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/ipykernel/__main__.py:130: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Can't handle mix of multilabel-indicator and binary",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-93ca4c293603>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Precision\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Recall\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"f1_score\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mprecision_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'precision'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m   1240\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[1;32m   1001\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1004\u001b[0m     \u001b[0mpresent_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         raise ValueError(\"Can't handle mix of {0} and {1}\"\n\u001b[0;32m---> 82\u001b[0;31m                          \"\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Can't handle mix of multilabel-indicator and binary"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import fce_api as fd\n",
    "import re\n",
    "import sklearn as sk\n",
    "import sklearn.metrics as skm\n",
    "\n",
    "# variables\n",
    "# data\n",
    "data = fd.extract_data('fce_train.gold.max.rasp.old_cat.m2')\n",
    "\n",
    "window_size = 3\n",
    "\n",
    "labels = []\n",
    "PAD = 0\n",
    "display_step = 1\n",
    "\n",
    "# classes\n",
    "has_error = 1\n",
    "no_error = 0\n",
    "\n",
    "# learning variables\n",
    "learning_rate = 0.0001\n",
    "epochs = 44\n",
    "batch_size = 2000\n",
    "\n",
    "\n",
    "# generating the word windows, including the spaces.\n",
    "def feed_windows_with_spaces(_data, _window_size):\n",
    "    windows = []\n",
    "    for sentence, errors in _data:\n",
    "        tokens = re.split(r'(\\s+)', sentence)\n",
    "        word_window_size = min(len(tokens), _window_size)\n",
    "        for i in range(0, len(tokens) - word_window_size + 1):\n",
    "            window_tuple = (tokens[i:i + word_window_size], )\n",
    "            window_range = range(round(i / 2), round((i + word_window_size) / 2))\n",
    "            for error in errors:\n",
    "                if error[0] in window_range or error[1] in window_range:\n",
    "                    if len(window_tuple) < 2:\n",
    "                        window_tuple = window_tuple + (has_error, )\n",
    "            if len(window_tuple) == 1:\n",
    "                window_tuple = window_tuple + (no_error, )\n",
    "            windows.append(window_tuple)\n",
    "    return windows\n",
    "\n",
    "\n",
    "# generating the word windows only with the tokens, excluding the spaces.\n",
    "def feed_windows_only_tokens(_data, _window_size):\n",
    "    windows = []\n",
    "    for sentence, errors in _data:\n",
    "        tokens = sentence.split()\n",
    "        word_window_size = min(len(tokens), _window_size)\n",
    "        for i in range(0, len(tokens) - word_window_size + 1):\n",
    "            window_tuple = (tokens[i:i + word_window_size], )\n",
    "            window_range = range(i, i + word_window_size)\n",
    "            for error in errors:\n",
    "                if error[0] in window_range or error[1] in window_range:\n",
    "                    if len(window_tuple) < 2:\n",
    "                        window_tuple = window_tuple + (has_error, )\n",
    "            if len(window_tuple) == 1:\n",
    "                window_tuple = window_tuple + (no_error, )\n",
    "            windows.append(window_tuple)\n",
    "    return windows\n",
    "\n",
    "feed_windows = feed_windows_only_tokens(data, window_size)\n",
    "# feed_windows = feed_windows[:200]\n",
    "# changing the training data\n",
    "print('feed_windows: ', '%d' % len(feed_windows), 'sentences: ', '%d' % len(data))\n",
    "\n",
    "# feed_windows = feed_windows[:42000]\n",
    "\n",
    "print('ready')       \n",
    "\n",
    "vocab = {'<PAD>': PAD}\n",
    "feed_windows_np = np.full([len(feed_windows), window_size], PAD)\n",
    "labels = np.full([len(feed_windows), 2], 2)\n",
    "\n",
    "for i, window in enumerate(feed_windows):\n",
    "    window_length = len(window[0]) \n",
    "    seq = np.full(window_length, 0)\n",
    "    for j, token in enumerate(window[0]):\n",
    "        if token not in vocab:\n",
    "            vocab[token] = len(vocab)\n",
    "        seq[j] = vocab[token]  \n",
    "    feed_windows_np[i, 0:window_length] = seq\n",
    "    if window[1] == has_error:\n",
    "        labels[i] = [0, 1]\n",
    "    else:\n",
    "        labels[i] = [1, 0]\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, window_size]) # data with the size of the window currently set to 6\n",
    "y = tf.placeholder(tf.float32, [None, 2])\n",
    "\n",
    "W = tf.Variable(tf.zeros([window_size, 2]))\n",
    "b = tf.Variable(tf.zeros([2]))\n",
    "\n",
    "# Construct model\n",
    "model = tf.matmul(x, W) # Sigmoid\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(model, y))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "\n",
    "predict = tf.argmax(model, 1)\n",
    "\n",
    "print(len(feed_windows_np))\n",
    "\n",
    "# Splitting to train and test\n",
    "train = feed_windows_np[:len(feed_windows_np)//2 - ((len(feed_windows_np)//2) % batch_size)]\n",
    "train_labels = labels[:len(feed_windows_np)//2 - ((len(feed_windows_np)//2) % batch_size)]\n",
    "test = feed_windows_np[(len(feed_windows_np) * 2) // 3:]\n",
    "test_labels = labels[(len(feed_windows_np) * 2) // 3:]\n",
    "total_batches = int(math.floor(len(train) / batch_size))\n",
    "\n",
    "avg_costs = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    init = tf.initialize_all_variables()\n",
    "    sess.run(init)\n",
    "    y_true = test_labels\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        for start, end in zip(range(0, len(train), 128), range(128, len(train) + 1, 128)):\n",
    "            sess.run(optimizer, feed_dict={x: train[start:end], y: train_labels[start:end]})\n",
    "        y_pred = sess.run(predict, feed_dict={x: test})\n",
    "        print(epoch, np.mean(y_true == y_pred))\n",
    "        print(\"Precision\", skm.precision_score(y_true, y_pred))\n",
    "        print(\"Recall\", skm.recall_score(y_true, y_pred))\n",
    "        print(\"f1_score\", skm.f1_score(y_true, y_pred))\n",
    "        # print(\"confusion_matrix\")\n",
    "        # print(sk.metrics.confusion_matrix(y_true, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
